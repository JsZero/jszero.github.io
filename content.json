{"pages":[{"title":"关于","text":"一个菜鸟码农的空间🏔 沿途的风景 🐕 家里的小柴犬“卷饼” 🎶 听过的演唱会 🍲 品尝过的美食","link":"/about/index.html"}],"posts":[{"title":"Akka使用教程","text":"Akka 是一个用 Scala 编写的库，用于在 JVM 平台上简化编写具有可容错的、高可伸缩性的 Java 和 Scala 的 Actor 模型应用，其同时提供了Java 和 Scala 的开发接口。Akka 允许我们专注于满足业务需求，而不是编写初级代码。在 Akka 中，Actor 之间通信的唯一机制就是消息传递。Akka 对 Actor 模型的使用提供了一个抽象级别，使得编写正确的并发、并行和分布式系统更加容易。Actor 模型贯穿了整个 Akka 库，为我们提供了一致的理解和使用它们的方法 ActorsIntroduction to Actors待补充","link":"/2022/07/02/Akka%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"},{"title":"DolphinScheduler源码阅读日记（三）通信机制","text":"概述DolphinScheduler的通信机制是通过Netty来实现的，在Netty上加做了一些封装和抽象 Netty简介功能介绍Netty 是一个基于 Java 的高性能网络应用框架，广泛用于开发高并发、低延迟的网络服务器和客户端。它提供了一组丰富的 API 和工具，简化了网络通信的开发过程，特别是在处理大量并发连接和数据流时。 为各种传输类型（阻塞和非阻塞socket）提供统一API 基于灵活且可扩展的事件模型，允许明确分离关注点 高度可定制的线程模型——单线程、一个或多个线程池（如 SEDA） 真正的无连接数据报socket支持（自3.1版起） 基础概念 table th:first-of-type {width: 20%;} table th:nth-of-type(2) {width: 80%;} 概念 含义 Channel Channel 是 Netty 中用于网络通信的基本抽象，表示一个到网络套接字（Socket）的连接。它类似于 Java NIO 的 Channel，但提供了更多的高级功能。Channel 可以是 TCP、UDP 或者文件传输等不同类型的连接 EventLoop EventLoop 是 Netty 中的事件处理核心。每个 EventLoop 都与一个或多个 Channel 关联，负责处理这些 Channel 上的所有 I/O 操作，包括读写事件的调度。EventLoop 使用单线程模式，可以有效地避免线程间竞争 ChannelHandler ChannelHandler 是用于处理 Channel 上的 I/O 事件的组件。Netty 通过 ChannelHandler 实现了灵活的事件处理机制。常见的 ChannelHandler 类型包括 ChannelInboundHandler 和 ChannelOutboundHandler，分别用于处理入站和出站数据 Pipeline Pipeline 是 Netty 中的一个重要概念，它是 ChannelHandler 的有序链表。所有与 Channel 相关的事件（如读、写、连接等）都会沿着 Pipeline 依次传递。开发者可以根据需要在 Pipeline 中插入不同的 ChannelHandler 来实现定制的逻辑 Bootstrap Bootstrap 是用于配置和启动客户端或服务器端 Channel 的类。它简化了网络应用程序的启动过程，开发者可以通过 Bootstrap 设置相关参数，如线程池、事件处理器等 ByteBuf ByteBuf 是 Netty 提供的用于高效处理字节数据的缓冲区。与 Java NIO 中的 ByteBuffer 不同，ByteBuf 提供了更多的操作方法，并且支持动态扩展、引用计数等特性，极大地提高了处理二进制数据的效率 Future&amp;Promise Future 和 Promise 是 Netty 中的异步编程模型，用于表示异步操作的结果。Future 表示一个尚未完成的操作结果，而 Promise 则是可以手动设置结果的 Future。这两个接口帮助开发者处理异步任务的回调逻辑 Transport Transport 是 Netty 中的底层抽象，负责实现具体的网络协议（如 TCP、UDP）的传输机制。不同的 Transport 实现可以有不同的 I/O 模型（如 NIO、Epoll 等），适用于不同的操作系统和性能需求 通信机制实现关键类在MasterServer、WorkerServer中分别都存在一个RpcServer和RpcClient，用于作为RPC的服务端和客户端 序列化与反序列化Messgae的序列化与反序列化 事件处理器如何映射到对应的Processor处理（值得借鉴）##","link":"/2024/08/23/DolphinScheduler%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E6%97%A5%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/"},{"title":"DolphinScheduler源码阅读日记（二）MasterServer工作流调度源码解析","text":"系统架构 MasterServer MasterServer采用分布式无中心设计理念，MasterServer主要负责 DAG 任务切分、任务提交监控，并同时监听其它MasterServer和WorkerServer的健康状态。 MasterServer服务启动时向Zookeeper注册临时节点，通过监听Zookeeper临时节点变化来进行容错处理。 MasterServer基于netty提供监听服务。 该服务内主要包含: DistributedQuartz: 分布式调度组件，主要负责定时任务的启停操作，当quartz调起任务后，Master内部会有线程池具体负责处理任务的后续操作； MasterSchedulerService: 是一个扫描线程，定时扫描数据库中的t_ds_command表，根据不同的命令类型进行不同的业务操作； WorkflowExecuteRunnable: 主要是负责DAG任务切分、任务提交监控、各种不同事件类型的逻辑处理； TaskExecuteRunnable: 主要负责任务的处理和持久化，并生成任务事件提交到工作流的事件队列； EventExecuteService: 主要负责工作流实例的事件队列的轮询； StateWheelExecuteThread: 主要负责工作流和任务超时、任务重试、任务依赖的轮询，并生成对应的工作流或任务事件提交到工作流的事件队列； FailoverExecuteThread: 主要负责Master容错和Worker容错的相关逻辑； 核心概念 table th:first-of-type {width: 25%;} table th:nth-of-type(2) {width: 75%;} 概念 含义 Process Definition 工作流定义 Process Instance 工作流实例，实际运行时会被包装为WorkflowExecuteRunnable Command 事件消息 关键流程分析 以下流程都在MasterServer中执行，不再在标题中赘述 拉取事件MasterSchedulerBootstrap是用于从MySQL中拉取事件（Command）的主要线程，在MasterServer启动时启动，通过findCommands()方法找到待执行的事件，这里的事件不仅限于开始执行工作流，还有其他类型，具体参考CommandType的定义，如下 而拉取事件流程中，如下 采用无中心节点设计，所以每个节点通过取模的方式获取当前节点应该处理的事件。节点总数和当前节点的序号是如何生成的呢？从注册中心（ZK/ETCD/JDBC）获取所有节点列表，在本地生成序号，详情参考org.apache.dolphinscheduler.service.queue.MasterPriorityQueue.ServerComparator 处理事件，创建工作流处理事件，创建工作流在，如下 而创建工作流具体分为如下几个阶段，ProcessDefinition -&gt; ProcessInstance (WorkflowInstance) -&gt; WorkflowExecuteContext -&gt; WorkflowExecuteRunnable，产生WorkflowExecuteRunnable实例即为最终需要调度的工作流 1234567891011121314// ProcessDefinition -&gt; ProcessInstance(WorkflowInstance)org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteContextFactory#createWorkflowExecuteRunnableContext:56org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteContextFactory#createWorkflowInstance:81org.apache.dolphinscheduler.service.process.ProcessServiceImpl#handleCommand:317org.apache.dolphinscheduler.service.process.ProcessServiceImpl#constructProcessInstance:768org.apache.dolphinscheduler.service.process.ProcessServiceImpl#generateNewProcessInstance:586// ProcessInstance(WorkflowInstance) -&gt; WorkflowExecuteContextorg.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnableFactory#createWorkflowExecuteRunnable:79org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteContextFactory#createWorkflowExecuteRunnableContext:67// WorkflowExecuteContext -&gt; WorkflowExecuteRunnableorg.apache.dolphinscheduler.server.master.runner.MasterSchedulerBootstrap#run:137org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnableFactory#createWorkflowExecuteRunnable:80 工作流被创建出来之后会生成一个工作流事件WorkflowEvent，放在内存的阻塞队列workflowEventQueue当中 调度工作流MasterSchedulerBootstrap线程启动后，还会再启动一个WorkflowEventLooper工作流事件处理线程，用于消费上一步放入内存的阻塞队列workflowEventQueue当中的工作流事件WorkflowEvent WorkflowEventLooper线程会使用WorkflowEventHandler处理工作流事件 WorkflowEventHandler会将通过调用WorkflowExecuteRunnable工作流的call()方法，将工作流的启动异步提交到WorkflowExecuteThreadPool线程池中执行 最终调用工作流的submitPostNode()方法，开始执行工作流的节点 解析工作流节点获取待提交的TaskNode列表submitTaskNodeList，并生成对应的TaskInstance实例TODO 解析过程比想象的复杂，需要详解分析下 将任务添加到内存中的standby优先级队列（堆）readyToSubmitTaskQueue中，并在开始提交任务 之后分发步骤比较复杂，具体拆解如下 1234567891011121314// 开始提交任务org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnable#submitStandByTask:1967// 生成任务实例（TaskExecuteRunnable）org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnable#executeTask:956// 开始分发任务实例org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnable#executeTask:993// 分发org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnable#tryToDispatchTaskInstance:1011// 使用TaskDispatchOperator分发org.apache.dolphinscheduler.server.master.runner.execute.DefaultTaskExecuteRunnable#dispatch:41 // 将任务添加到globalTaskDispatchWaitingQueue中org.apache.dolphinscheduler.server.master.runner.operator.TaskDispatchOperator#handle:34// GlobalTaskDispatchWaitingQueueLooper线程轮询queue，使用BaseTaskDispatcher分发任务实例给workerorg.apache.dolphinscheduler.server.master.runner.GlobalTaskDispatchWaitingQueueLooper#run:79 最后使用找到可用worker节点，通过rpc启动待执行任务","link":"/2024/07/28/DolphinScheduler%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E6%97%A5%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89MasterServer%E5%B7%A5%E4%BD%9C%E6%B5%81%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"DolphinScheduler源码阅读日记（一）开发环境搭建","text":"系统环境 环境 版本 系统 macOS 12.2.1/m1 pro JRE Zulu 8.62.0.19-CA-macos-aarch64 Maven 3.8.6 Node 18.4.0 Pnpm 7.3.0 Zookeeper 3.8.4 MySQL 8.0.28 DolphinScheduler 3.2.0 搭建项目开发环境项目下载从github下载源码从dolphinscheduler源码仓库下载源码 12git clone https://github.com/apache/dolphinschedulergit checkout 3.2.0 # 切换到3.2.0分支 Zookeeper下载二进制可执行包 下载Zookeeper 3.8.4二进制可执行包 创建文件&amp;日志目录 解压压缩包，创建data、datalog目录 123cd /Users/jiashaoqi/plugin/zookeepertar -zxvf apache-zookeeper-3.8.4-bin.tar.gzmkdir data datalog 修改配置文件将conf目录下的zoo_sample.cfg文件，复制一份，重命名为zoo.cfg，修改其中数据和日志的配置，如： 123cd ./apache-zookeeper-3.8.4-bin/confcp zoo_sample.cfg zoo.cfgvi zoo.cfg 添加环境变量12vi ~/.bash_profile # 添加内容如下source ~/.bash_profile 启动Zookeeper1zkServer.sh start # 见到如图所示即为启动成功 MySQL数据库配置初始化数据库及账号创建完新数据库dolphinscheduler后，将dolphinscheduler/dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql下的sql文件直接在MySQL中运行，完成数据库初始化 1234567891011121314151617181920mysql&gt; create database dolphinscheduler;Query OK, 1 row affected (0.01 sec)mysql&gt; create user 'dolphin'@'localhost' identified by 'nihplod';Query OK, 0 rows affected (0.01 sec)mysql&gt; grant all privileges on dolphinscheduler.* to 'dolphin'@'localhost';Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; use dolphinscheduler;Database changedmysql&gt; source /Users/jiashaoqi/workspace/idea/dolphinscheduler/dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql;Query OK, 1 row affected (0.00 sec)...Query OK, 1 row affected (0.00 sec) 后端Maven依赖下载通过idea打开项目，下载依赖，这可能需要一段时间 注意：maven下载依赖可能会出现问题，对于下载出错的依赖或者插件，可以到本地maven仓库目录下删除对应的子目录重新下载，如在下载依赖后编译时发生了如下异常 1java: 读取/Users/jiashaoqi/plugin/maven/apache-maven-3.8.6/repo/io/fabric8/kubernetes-model-core/5.10.2/kubernetes-model-core-5.10.2.jar时出错; zip file is empty 所以手动下载依赖kubernetes-model-core 12rm -rfv /Users/jiashaoqi/plugin/maven/apache-maven-3.8.6/repo/io/fabric8/kubernetes-model-core/5.10.2mvn dependency:get -DgroupId=io.fabric8 -DartifactId=kubernetes-model-core -Dversion=5.10.2 修改数据库配置 将dolphinscheduler-bom/pom.xml文件中mysql-connector-java依赖的scope修改为compile 将如下配置文件中的mysql的datasource配置为如下内容12345dolphinscheduler-master/src/main/resources/application.yaml:151dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/resources/application.yaml:93dolphinscheduler-api/src/main/resources/application.yaml:229dolphinscheduler-standalone-server/src/main/resources/application.yaml:305dolphinscheduler-tools/src/main/resources/application.yaml:49 配置名 配置值 datasource.driver-class-name com.mysql.cj.jdbc.Driver datasource.url jdbc:mysql://127.0.0.1:3306/dolphinscheduler datasource.username dolphin datasource.password nihplod 修改日志级别为以下配置增加一行内容 使日志能在命令行中显示 123dolphinscheduler-master/src/main/resources/logback-spring.xmldolphinscheduler-worker/src/main/resources/logback-spring.xmldolphinscheduler-api/src/main/resources/logback-spring.xml 12345&lt;root level=&quot;INFO&quot;&gt;+ &lt;appender-ref ref=&quot;STDOUT&quot;/&gt; &lt;appender-ref ref=&quot;APILOGFILE&quot;/&gt; &lt;appender-ref ref=&quot;SKYWALKING-LOG&quot;/&gt;&lt;/root&gt; 可以再在STDOUT这个appender的pattern上套一个%clr(...)，让日志在控制台上高亮显示，如 12345678910111213&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;120 seconds&quot;&gt;+ &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot; /&gt; &lt;!-- ... --&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;+ %clr([%level] %date{yyyy-MM-dd HH:mm:ss.SSS Z} %logger{96}:[%line] - [WorkflowInstance-%X{workflowInstanceId:-0}][TaskInstance-%X{taskInstanceId:-0}] - %msg%n) &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- ... --&gt;&lt;/configuration&gt; 编译源代码 运行后端服务参考DolphinScheduler 普通开发模式需要启动三个服务，包括 MasterServer，WorkerServer，ApiApplicationServer MasterServer：在 Intellij IDEA 中执行 org.apache.dolphinscheduler.server.master.MasterServer 中的 main 方法，并配置 VM Options -Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql WorkerServer：在 Intellij IDEA 中执行 org.apache.dolphinscheduler.server.worker.WorkerServer 中的 main 方法，并配置 VM Options -Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql ApiApplicationServer：在 Intellij IDEA 中执行 org.apache.dolphinscheduler.api.ApiApplicationServer 中的 main 方法，并配置 VM Options -Dlogging.config=classpath:logback-spring.xml -Dspring.profiles.active=api,mysql。启动完成可以浏览 Open API 文档，地址为 http://localhost:12345/dolphinscheduler/swagger-ui/index.html 前端安装依赖，运行前端服务123cd dolphinscheduler-uipnpm installpnpm run dev 截止目前，前后端已成功运行起来，浏览器访问 http://localhost:5173 ，并使用默认账户密码 admin/dolphinscheduler123 即可完成登录 完成环境搭建搭建成功效果","link":"/2024/07/27/Dolphinscheduler%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E6%97%A5%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"Flink源码编译","text":"前言学习一下Flink的执行原理，需要在本地编译源码好debug运行。 编译环境 环境 版本 系统 m1 pro macbook pro 14 JRE Zulu 8.62.0.19-CA-macos-aarch64 Flink release-1.12.7-rc1 编译过程1mvn clean package -DskipTests -Dhadoop.version=2.7.1 参考下Building Apache Flink from Source 编译过程中产生如下异常并解决 报错：安装node和npm失败1[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.6:install-node-and-npm (install node and npm) on project flink-runtime-web_2.11: Could not download Node.js: Could not download https://nodejs.org/dist/v10.9.0/node-v10.9.0-darwin-arm64.tar.gz: nodejs.org:443 failed to respond -&gt; [Help 1] 解决方案：参考eirslett/frontend-maven-plugin issue 952，FLINK-23230提到的问题修改flink/flink-runtime-web/pom.xml文件中frontend-maven-plugin的版本为1.11.0，发现还是有443异常，后来发现是maven的settings.xml中配置的proxy走的是sock5，修改成http代理后恢复正常","link":"/2022/07/03/Flink%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"},{"title":"Java-语言基础","text":"概念编译型语言和解释型语言的区别 编译型语言：在程序执行之前，整个源代码会被编译成机器码或者字节码，生成可执行文件。执行时直接运行编译后的代码，速度快，但跨平台性较差。 解释型语言：在程序执行时，助航解释执行源代码，不生成独立的可执行文件。通常由解释器动态解释并执行代码，跨平台性好，但执行速度相对较慢。典型的编译型语言如C、C++，但型的解释型语言如Python、JavaScript 数据类型基础数据类型及其包装类型，缓存池关于几种初始化Integer方式，初始化对象的区别 代码示例 >folded12345678910111213141516171819202122public class Main { public static void main(String[] args) { Integer i = new Integer(100); Integer j = new Integer(100); System.out.println(i == j); // false new每次在堆生成新的对象 Integer i = new Integer(100); Integer j = 100; System.out.println(i == j); // false new新建堆对象，自动装箱使用Integer.valueOf，会尝试获取缓存的对象（-128～127） Integer i = 100; Integer j = 100; System.out.println(i == j); // true 获取的时缓存池中的对象 Integer i = 128; Integer j = 128; System.out.println(i == j); // false 超过缓存池范围 i = new Integer(100); int k = 100; System.out.println(1 == k); // true 包装数据类型之间比较的是内存地址，基本数据类型之间比较的是值，包装数据类型和基本数据类型比较，会先拆箱成基本数据类型，所以比的也是值 }} 面向对象特性：封装、继承、多态泛型集合多线程版本特性","link":"/2025/03/30/Java-%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"},{"title":"Java-JVM原理","text":"Java内存模型 JMMTODO JVM内存区域 程序计数器：线程私有的，jvm通过改变计数器的值来选取下一条需要执行的字节码指令，唯一一个没有规定任何OutOfMemoryError情况的区域 Java虚拟机栈：线程私有的，每个方法执行时创建栈帧，方法被调用就是栈帧在栈中从入栈到出栈的过程。栈帧的组成部分如下， 局部变量表：存放编译期可知的各种jvm基本数据类型、对象引用。todo 待完善 操作数栈： 动态链接： 方法返回地址： 本地方法栈：线程私有的，本地（Native）方法所使用的栈 Java堆：线程共享的，分配内存创建存储对象实例的主要内存区域。在即时编译（JIT）的栈上分配、标量替换等技术下，也可以分配在其他区域 分配缓冲区：即TLAB（Thread Local Allocation Buffer），用于优化内存分配速度，避免线程并行导致分配内存冲突而提前为线程预留内存 方法区：线程共享的，也称永久代，用于存储已被jvm加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。在jdk8以后被本地内存中实现的元空间（Meta-space）代替 运行时常量池：方法区的一部分。Class文件中除了类版本、字段、方法、接口等信息外，还有一项信息是常量池表，用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中 直接内存：不是jvm运行时数据区的一部分，NIO中使用，基于Channel与Buffer的I/O方式，直接分配堆外内存，避免java堆和Native堆之间的数据赋值，从而显著提升性能 类加载机制类加载时机 new实例化类对象，读取或者设置类的静态字段（final修饰编译期把结果放入常量池的静态字段除外），调用一个类的静态方法时 对类型进行反射调用 当初始化子类的时候，发现父类还未初始化，会初始化父类 … 类的生命周期 加载 验证 准备 解析 初始化 使用 卸载：卸载的前提有3个 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象 该类没有在其他任何地方被引用 该类的类加载器的实例已被 GC 类加载器机制三层类加载器、双亲委派的类加载架构 类加载器（Class Loader） 启动类加载器（Bootstrap Class Loader）：C++语言编写，JVM的一部分。责加载存放在&lt;JAVA_HOME&gt;\\lib目录，或者被-Xbootclasspath参数所指定的路径中存放的，而且是Java虚拟机能够识别的类库加载到虚拟机的内存中 扩展类加载器（Extension Class Loader）：负责加载&lt;JAVA_HOME&gt;\\lib\\ext目录中，或者被java.ext.dirs系统变量所指定的路径中所有的类库 应用程序类加载器（Application Class Loader）：也称为“系统类加载器”。它负责加载用户类路径（ClassPath）上所有的类库，开发者同样可以直接在代码中使用这个类加载器 双亲委派模型双亲委派模型的工作过程：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载 破坏双亲委派模型 线程上下文类加载器 SPI OSGi 类的卸载条件对象的创建过程 常量池中尝试定位类的符号引用，判断类是否被加载、解析和初始化过。如果没有先做类加载 为对象分配内存。内存规整使用“指针碰撞”，内存零散使用“空闲列表”。处理线程申请内存的冲突，可以选择使用cas失败重试或者TLAB 内存空间初始化为零值，（TLAB方式也可以提前到TLAB分配时进行） 初始化对象头信息，类的元数据信息、哈希码、对象的gc分代年龄。根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式 执行类构造函数创建实例 垃圾回收理论判断对象是否应该被回收 引用计数法：引用一次计数+1。存在循环引用的问题，比如map大对象需要嵌套引用关系 引用类型 强引用 软引用 弱引用 虚引用 可达性分析：通过GC Roots根据引用关系向下搜索，到达不了的对象就是需要被回收的 可作为GC Roots的对象： 虚拟机栈中引用的对象，比如参数、局部变量、临时变量等 类静态属性引用的变量 常量引用的对象 JNI引用的对象 sychronized同步锁持有的对象 … 垃圾回收算法 分代收集理论：根据以下理论，一般将jvm堆划分成新生代和老年代，对不通的区域单独进行gc 弱分代假说：绝大多数对象都是朝生夕灭的 强分代假说：熬过越多次垃圾回收的对象就越难被回收 标记-清除算法：标记阶段，标记所有需要回收的对象，回收阶段，统一回收掉所有被标记的对象。但是存在如下缺点 当存在大量对象需要被回收时，标记和回收的效率随着对象增多而降低 内存空间碎片化，大对象无法分配足够的连续内存，而引发额外的gc动作 标记-复制算法：也叫做复制算法。针对的新生代对象的存亡特征：朝生夕灭。将堆划分成一块Eden空间和两块较小的Survivor空间（默认8:1），每次只用一块Eden空间和一块Survivor空间，每次gc时将存活的对象复制到剩下的一块Survivor空间中，清除Eden空间和使用过的Survivor空间。Survivor空间不足一次gc的时候，一般会用老年代做分配的担保 标记-整理算法：针对老年代独享的存亡特征：难以回收。标记阶段同“标记-清除算法”，清理阶段让所有存活的对象都向内存空间的一端移动，然后直接清理掉边界以外的内存 注：标记-清除算法所带来的jvm停顿会更小，但是由于内存分配和访问的频率比gc要高，标记-整理算法的吞吐量会更高。所以关注延迟的CMS是基于标记-清除算法的，关注吞吐的Parallel Scavenge是基于标记-整理算法的 回收相关算法细节 根结点枚举：方法区比较大，查找GC Root耗时较长。使用OopMap直接存放对象引用位置，提高查找效率 安全点：在执行到“长时间执行”的位置生成OopMap，这些位置被称为安全点。这些位置是执行序列复用的地方，比如方法调用、循环跳转、异常跳转 线程执行到安全点如何停顿：抢占式中断，一般不用。主动式中断，设置标志位等待线程运行到安全点自己主动挂起 安全区域：未分配到时间分片的线程，如sleep或者blocked状态的线程。这种能确保在某一段代码中，引用关系不会发生变化的区域，被称为安全区域 记忆集与卡表：新生代和老年代之间可能存在引用关系，为了避免对新生代回收时扫描整个老年代，在新生代中建立了记忆集的数据结构。卡表是记忆集的一种具体实现，定义了记忆集的记录精度，与堆内存的映射关系等，卡表标识的每一个内存块叫卡页，存在跨代引用会将卡页刷脏，脏页在回收时是需要被扫描的 写屏障：写屏障可以看作在虚拟机层面对“引用类型字段赋值”这个动作的AOP切面，在这个切面上可以维护卡表状态 并发的可达性分析：使用三色标记法实现 颜色种类 白色：对象尚未被垃圾收集器访问过。分析开始所有对象是白色，分析结束只有不可达的对象是白色 黑色：表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色对象不可能指向白色对象 灰色：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过 如何避免对象误标记：用户线程和标记线程并发运行，可能标记过后节点是白色但是新增了引用关系应该为黑色，如果不处理，该节点会被错误地回收掉 误标记出现条件 增加了一条或者多条从黑色对象到白色对象的引用 删除了全部从灰色对象到白色对象的直接或间接引用 解决方案：（两种方案任选其一） 增量更新（Incremental Update）：新增黑色指向白色的引用时，记录这个引用关系。并发扫描结束之后，再以黑色对象为根重新扫描一次。CMS的实现方式 原始快照（SATB，Snapshot At The Beginning）：删除灰色指向白色的引用时，记录这个引用关系。并发扫描结束之后，再以灰色对象为根重新扫描一次。G1、Shenandoah的实现方式 垃圾回收器垃圾回收器之间的组合关系 Serial收集器特点：gc时必须暂停其他工作线程直至gc结束优点：简单高效，额外内存开销小，适用于资源受限的环境。客户端模式下可以使用，比如桌面应用缺点：停顿时间较长，体验较差 ParNew收集器特点：Serial收集器的多线程并行版本。除了Serial收集器外，目前只有它能与CMS收集器配合工作 Parallel Scanvenge收集器特点：新生代收集器，基于标记-复制算法实现，也是能并行收集的多线程收集器。该收集器目标是达到一个可控制的吞吐量。-XX：MaxGCPauseMillis设置最大停顿时间，设置越小相对地gc越频繁，-XX：GCTimeRatio设置gc时间占总时间的比例。除此之外，-XX：+UseAdaptiveSizePolicy可以设置自适应调节，无需指定Eden，Survivor区大小，收集器会自动调节以做到最优吞吐 Serial Old收集器特点：是Serial收集器的老年代版本，单线程收集器，使用标记-整理算法。该收集器的主要意义也是供客户端模式下的JVM使用。服务端模式下，有两种用途，一是JDK 5以及之前的版本中与Parallel Scavenge收集器搭配，二是另外一种就是作为CMS收集器发生失败时的后备预案，在并发收集发生Concurrent Mode Failure时使用 Parallel Old收集器特点：Parallel Old是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现。在注重吞吐量或者处理器资源较为稀缺的场合，都可以优先考虑这个组合 CMS收集器特点：一种以获取最短回收停顿时间为目标的收集器，基于标记-清除算法实现的步骤： 1. 初始标记：标记一下GC Roots能直接关联到的对象，停顿较短 2. 并发标记：从GC Roots的直接关联对象开始遍历整个对象图，与用户线程并发 3. 重新标记：为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，停顿较长 4. 并发清除：清理删除掉标记阶段判断的已经死亡的对象，与用户线程并发 初始标记、重新标记两步需要“Stop The World” 优点： 并发收集，低停顿 缺点： 对处理器资源非常敏感。在并发阶段，它虽然不会导致用户线程停顿，但却会因为占用了一部分cpu资源而导致应用程序变慢，降低总吞吐量 无法处理“浮动垃圾”，可能出现“Concurrent Mode Failure”失败进而导致另一次完全“Stop The World”的Full GC的产生。CMS运行期间预留的内存无法满足程序分配新对象，即“Concurrent Mode Failure”，需要临时启用Serial Old收集器来重新进行老年代的垃圾收集 浮动垃圾：并发标记和并发清理阶段，用户线程还在继续运行，程序在运行不断产生新的垃圾对象，但这部分垃圾无法在当次GC被标记处理，只好留待下一次GC时再清理。这一部分垃圾就称为“浮动垃圾” 收集结束时会有大量空间碎片产生。碎片过多时，往往会出现老年代还有很多剩余空间，但无法找到足够大的连续空间来分配当前对象，而不得不提前触发一次Full GC的情况。-XX：+UseCMS-CompactAtFullCollection参数可以指定full gc时整理内存碎片，-XX：CMSFullGCsBefore-Compaction参数可以指定进行n次不整合碎片的full gc之后，下次full gc之前先整理碎片 Garbage First收集器（G1）特点：基于Region的内存布局形式，面向服务端应用的垃圾收集器。建立起“停顿时间模型”，把连续的Java堆划分为多个大小相等的独立区域（Region），每一个Region根据需要，扮演新生代的Eden空间、Survivor空间，或老年代空间。将Region作为单次回收的最小单元，后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间（-XX：MaxGCPauseMillis），优先处理回收价值收益最大的那些Region。每个Region都维护有自己的记忆集，G1至少要耗费大约相当于Java堆容量10%至20%的额外内存来维持收集器工作 停顿时间模型：能够支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标 步骤： 1. 初始标记：标记一下GC Roots能直接关联到的对象，停顿较短 2. 并发标记：从GC Roots的直接关联对象开始遍历整个对象图，与用户线程并发 3. 最终标记：对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录，停顿较短 4. 筛选回收：更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据期望的停顿时间制定回收计划，把决定回收的部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的全部空间，涉及存活对象的移动，必须暂停用户线程 G1收集器除了并发标记外，其余阶段也是要完全暂停用户线程的，换言之，它并非纯粹地追求低延迟，官方给它设定的目标是在延迟可控的情况下获得尽可能高的吞吐量 优点： 可以指定最大停顿时间、分Region内存布局、收益动态确定回收集合 从整体来看是基于“标记-整理”算法实现的收集器，但从局部（两个Region之间）上看又是基于“标记-复制”算法实现，不会产生内存空间碎片 缺点： 额外内存占用和执行负载比CMS要高（Region粒度的卡表，以及卡表更复杂的维护）","link":"/2025/03/30/Java-JVM%E5%8E%9F%E7%90%86/"},{"title":"Kafka原理和实践","text":"Kafka部署方案选择 操作系统 I/O模型的选择：I/O模型：阻塞IO、非阻塞IO、IO多路复用、信号驱动IO、异步IO几种模型。Java Socket对象的阻塞&amp;非阻塞模式对象前两种；Linux的select函数属于IO多路复用；epoll系统调用介于第三四种模型之间；第五种模型Linux少有支持，Windows由OCP线程模型。Kafka客户端底层使用了Java的selector实现，selector在Linux上实现机制是epoll，Windows上实现机制是select。因此Kafka部署在Linux上更有优势，I/O性能更强。 零拷贝支持：从磁盘读取数据发送到网络当中去经过几个阶段，磁盘→内核缓存区→应用程序内存→socket缓冲区→网络，使用内存映射文件技术可以用应用程序逻辑地址映射内核缓冲区地址，避免内核缓冲区和应用程序内存间的数据拷贝。使用零拷贝技术，可以直接把内核缓冲区的数据映射到Socket缓冲区，网卡读取数据发送到网络中时，直接读取的是内核缓冲区数据。Linux平台支持零拷贝机制，Windows在后期才支持。 社区支持：社区对Window支持比较差，对bug修复没有承诺。 磁盘类型：机械硬盘还是固态硬盘，机械硬盘就可以了，Kakfa的顺序读写操作避免了机械硬盘随机读写慢的问题 磁盘容量：需要根据新增消息数量、消息留存时间、平均消息大小、备份数、压缩方式估算容量 带宽：一般是1Gbps千兆网络或者10Gbps万兆网络，根据sla（多长时间处理多少大小的消息）估算服务器数量，跨机房传输另算 分区策略轮询策略随机策略按消息键保序策略 保证消息不丢失kafka对已提交的消息做有限度的持久化保证已提交的消息：kafka的若干broker成功接收到消息写入文件后，会告诉生辰着已经成功提交。有限度的持久化保证：N个broker至少有一个存活 消息丢失的场景生产者丢失数据： 由于生产者逻辑，网络等原因导致发送失败，可以使用带有callback的send接口做异常重试。 由于broker故障导致发送失败，需要处理broker端问题不管怎么说，上述场景的消息都是未提交的，kafka无法保证消息不丢失消费者丢失数据： 先处理消息，再提交offset的的模式，如果消息处理到一半失败了，offset已经提交了就无法再消费该消息了，消息没有完整地被处理，即被丢失了 保证消息不丢失的最佳实践 使用带有callback的send方法，做好重试 ack级别由三种，分别是0,1,all，0是不等待服务器确认，1（默认模式）是等待leader确认，all是等待ISR中所有副本写入成功确认 broker端设置落后太多的follower不允许竞选成为leader replication.factor副本因子多配置一些，最好大于等于3 消费端关闭自动提交，自动提交会以一定的频率定时在后台做提交 自动提交的问题 重复消费：处理完了还未ack，服务崩溃或者rebalance，消息被重新拉取处理 消息丢失：排队处理未处理就commit，此时服务崩溃，消息已经commit不会再被消费 引申：ISR机制，ack级别设置为all的情况下，如果有一台broker挂了，那么生产者生产消息可能由于一台机器无法应答而一直无法ack，为了避免这种情况，采用了ISR机制，如果某台follower长时间无响应会被踢出ISR todo：kafka批量消费的设计方式，多线程+滑动窗口；kafka延迟队列的设计方式 生产者TCP连接管理为什么选择TCP而不是HTTP？ 能够使用TCP提供的高级功能，比如多路复用请求（复用长连接）及同时轮询多个连接的能力 TCP协议头更小，高吞吐下消耗更小 TCP可自定义序列化方式，HTTP只能使用纯文本格式（如json） 管理TCP连接的方式 KafkaProducer实例创建的时候启动Sender线程，创建与boostrap.servers中所有broker的tcp连接（虽然不那么合理） KafkaProducer实例首次更新元数据信息之后，还会再次创建与集群中所有Broker的TCP连接 Producer端发送消息到某台Broker时发现没有连接也会建连 如果Producer端connections.max.idle.ms参数大于0，1中创建的TCP连接会被自动关闭；如果该参数=-1，1中创建的TCP连接不会关闭，会成为僵尸连接 Kafka生产者幂等&amp;事务幂等和事务是同两个能力，Kafka默认只支持至少一次的语义幂等效果：保证topic的一个分区上不出现重复消息方式：设置producer的enable.idempotence为true原理： 给每个producer分配唯一的producerId 每条消息附带上一个递增的sequence number Broker端检查sequence number，重复的消息被丢弃事务效果：跨分区，跨topic的原子性写入，确保“要么都成功，要么都失败”方式： 开启幂等 设置事务id transaction.id 使用initTransaction() → beginTransaction() → send → commitTransaction()方式发送消息原理：Kafka会记录每个事务的状态，并写入一个内部事务日志，只有提交成功的事务，消费者才能读取对应的消息 Kafka rebalance原理如何保证消息不重复","link":"/2025/05/06/Kafka%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E8%B7%B5/"},{"title":"MySQL原理和实践","text":"一条SQL的执行过程 客户端连接到服务端的连接器 分析器进行词法分析（解析关键字和字段名）和语法分析（判断是否符合MySQL语法） 如果是查询语句，有缓存则查缓存 优化器决定SQL的执行顺序 表权限校验，执行器调用存储引擎读写接口进行操作。如果是InnoDB写操作具体流程是 调用查询接口查询数据 查询引擎从磁盘读取到内存,返回数据 执行器变更数据，调用查询引擎写入数据 新数据更新到内存，写入redolog 执行器写binlog 提交事务，写数据 redolog 和 binlog对比 对比项 redo log binlog 属于哪个模块 InnoDB 存储引擎 MySQL Server 层（与存储引擎无关） 作用 用于 崩溃恢复，保证事务持久性 用于 主从同步、备份恢复、审计等 写入时机 事务提交前就写入 事务提交时统一写入 内容格式 物理日志（记录页的物理变化） 逻辑日志（记录 SQL 或数据变更操作） 是否可部分持久 是（prepare 阶段后就写） 否（只在事务 commit 时才写） 是否可重做恢复 是 否，只能用于逻辑重放（不保证完整性） 是否被 binlog_format 影响 否 是（可选 statement/row/mixed） 写入过程2PC两阶段提交，具体过程如下 写入 binlog（未 fsync） 写入 redolog 的 prepare 阶段（未提交） fsync binlog（落盘） 写入 redolog 的 commit 标记 返回“提交成功”Q：如何做到崩溃恢复的？A： redo log状态 binlog 状态 崩溃恢复后的处理 无 prepare 无 事务未开始，无需处理 prepare ✔ 无/未 flush 回滚 prepare ✔, commit ✔ ✔ flush 重做 事务四大特性ACIDAtomicity（原子性）：事务中的所有操作要么全部完成，要么全部不做Consistency（一致性）：事务执行前后，数据库必须保持一致性约束Isolation（隔离性）：多个事务并发执行时，彼此不能相互干扰Durability（持久性）：一旦事务提交，数据必须永久保存，即使系统崩溃 事务的隔离级别 隔离级别 脏读 不可重复读 幻读 Read Uncommitted ✅ 是 ✅ 是 ✅ 是 Read Committed ❌ 否 ✅ 是 ✅ 是 Repeatable Read ❌ 否 ❌ 否 ✅ 是（InnoDB 实现中为 ❌） Serializable ❌ 否 ❌ 否 ❌ 否 脏读（Dirty Read）含义：读到未提交事务写的数据。例子：事务 A 改了一个值还没提交，事务 B 就读到了这个值。如果 A 回滚了，B 读到的是不存在的脏数据。 不可重复读（Non-repeatable Read）含义：同一个事务内，两次读取同一行返回了不同结果。例子：事务 A 先查一次 name=’Alice’ 的年龄，事务 B 改了年龄并提交，事务 A 再查年龄变了。 幻读（Phantom Read）含义：事务中按条件读出一批数据，后续再读发现“幻影”数据（多出或少了行）。例子：事务 A 查 age &gt; 20 的行，事务 B 插入一个 age = 22 并提交，事务 A 再查时结果变了。 MVCCMVCC，全称是 Multi-Version Concurrency Control（多版本并发控制），是 InnoDB 用来实现事务隔离的关键机制。在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 索引数据结构B+树 覆盖索引在普通索引上，叶节点上存储了相关字段和主键的数据，如果查询的是这部分字段可以避免回表查询，提高查询效率，减少树的搜索次数，显著提升查询性能 主键的选择 自增主键的插入可以以追加模式添加数据，避免中间插入导致B+树页分裂 普通索引页子节点存储的是主键，因此主键越小越好 当前读和快照读","link":"/2025/05/07/MySQL%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E8%B7%B5/"},{"title":"MySQL实战45讲-阅读笔记","text":"SQL查询语句的执行执行流程如下具体拆解如下， 连接器 长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。使用长连接可能会导致MySQL占用内存快速上涨，原因是执行过程中临时使用的内存是管理在连接对象里面的，这些资源会在连接断开的时候才释放。解决方案有两个 定期断开长连接 MySQL 5.7或更新版本可以执行mysql_reset_connection来重新初始化连接资源 查询缓存 除非是静态表，否则不建议开启查询缓存。表只要有一次更新操作，表关联所有缓存都失效。MySQL 8.0及以上缓存功能已被废弃 分析器：依次进行如下分析，不符合词法或语法则抛出异常 ①词法分析：解析关键字和字段名 ②语法分析：判断是否符合MySQL语法 优化器：决定SQL的执行顺序 执行器：表权限校验，调用查询引擎接口根据索引（如果有）查询数据 SQL更新语句的执行执行流程和查询语句的流程一样，如下 redo log和binlog除此以外，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志） redo log - InnoDB引擎特有的日志，可以保证crash-safe。 - 物理日志，记录的是“在某个数据页上做了什么修改”。 - 循环写的，空间固定会用完。如下所示，write pos是当前记录的位置，一边写一边后移，checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos和checkpoint之间的是还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示redolog满了不能再执行新的更新，得停下来先擦掉一些记录写入binlog，把checkpoint推进一下。 binlog - MySQL的Server层实现的，所有引擎都可以使用，用于归档。 - 逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1”。 - 可以追加写入的。binlog文件写到一定大小后会切换到下一个，不会覆盖以前的日志。 update语句的执行流程update语句的执行流程如下，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。redo log的写入拆成了两个步骤：prepare和commit，也就是”两阶段提交”。 🔥事务的隔离级别隔离性与隔离级别 table th:first-of-type {width: 25%;} table th:nth-of-type(2) {width: 75%;} 级别 含义 读未提交 一个事务还没提交时，它做的变更就能被别的事务看到 读提交 一个事务提交之后，它做的变更才会被其他事务看到 可重复读 一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的 串行化 对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行 级别 结果 读未提交 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2 读提交 则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2 可重复读 则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的 串行化 则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2 🔥事务隔离的实现事务隔离具体是怎么实现的，这里以“可重复读”为例展开说明一下。 在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view.如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。回滚日志不会一直保留，在不需要的时候才删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。所以不建议用长事务，长事务意味着系统里面会存在很老的事务视图，因此回滚日志会占用大量存储资源，还占用锁资源，也可能拖垮整个库。 深入浅出索引索引的数据结构哈希表：适用于只有等值查询的场景 有序数组：在等值查询和范围查询场景中的性能就都非常优秀。但是插入效率较低，只适用于静态存储引擎 搜索树：使用N叉搜索树 为什么不使用二叉搜索树：索引数据存储在磁盘上，二叉搜索树节点只存储一个数据，树比较高，一次查询需要更多次的数据块读取 InnoDB 的索引模型在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用了B+树索引模型，数据都是存储在B+树中。 每一个索引在InnoDB里面对应一棵B+树。以如下的建表语句为例，索引树结构如下图所示 12345create table T( id int primary key, k int not null, name varchar(16),index (k))engine=InnoDB; 主键索引：也叫聚簇索引，叶子节点存的是整行数据普通索引：也叫二级索引，非聚簇索引，叶子节点内容是主键的值 Q：基于主键索引和普通索引的查询有什么区别？A：主键查询方式，则只需要搜索主键这棵B+树。普通索引查询方式，则需要先搜索普通索引树，得到叶节点上的主键值，再到主键索引树搜索一次。这个过程称为回表 索引维护B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。 如果插入一个更大的值，只需要在最后面插入一个新记录。 如果在中间插入一个值，处理比较麻烦，需要逻辑上挪动后面的数据，空出位置。 而更糟的情况是，如果数据所在的数据页已经满了，根据B+树的算法，需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂，插入性能因此会受到影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。 Q：哪些场景下应该使用自增主键，而哪些场景下不应该?A： 自增主键的插入数据模式，正符合递增插入的场景。每次插入一条新记录都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。其次，在考虑主键字段的选择时，由于普通索引的叶节点存储的是主键，因此主键越小普通索引占用的空间就更小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。 覆盖索引在普通索引上，叶节点上存储了相关字段和主键的数据，如果查询的是这部分字段可以避免回表查询，提高查询效率，减少树的搜索次数，显著提升查询性能 最左前缀原则B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。 Q：在建立联合索引的时候，如何安排索引内的字段顺序？A： 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。如果既有联合查询，又有基于a、b各自的查询呢？这时候需要同时维护类似(a,b)、(b) 这两个索引。此时，我们要考虑的原则就是空间，比如上有两个字段name、age，name字段是比age字段大的 ，那我就建议你创建一个（name,age)的联合索引和一个(age)的单字段索引。 索引下推举例，比如表存在name、age的联合索引，在执行如下语句时， 1select * from tuser where name like '张%' and age=10 and ismale=1; 如果没有索引下推，会回表依次查询记录的age、ismale是否符合要求 如果存在索引下推（MySQL5.6引入），会先根据索引上的数据对age进行过滤，再回表查询记录的ismale是否符合要求，这样的回表次数会更少 🔥锁机制根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类。 全局锁顾名思义，全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的典型使用场景是，做全库逻辑备份。 如果库下的表都是InnoDB表，在使用逻辑备份工具mysqldump时可以使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。 表级锁MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL）。表锁的语法是 lock tables … read/write。与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。 另一类表级的锁是MDL（metadata lock）。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 Q：为什么修改表结构操作可能出现问题？A： 如果表正在被读，一些session因此获取了读锁，在进行修改表结构操作获取写锁的时候就会阻塞住，此时如果再发生其他申请读锁的session，这些session也会全部被阻塞住。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新session再请求的话，这个库的线程很快就会爆满。 Q：如何安全地给小表加字段？A： 首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。如果要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，该怎么做呢？为alter table操作增加超时 🔥行锁MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，这就会影响到业务并发度。InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。 🔥两阶段锁协议在下面的操作序列中，事务B的update语句执行时会是什么现象呢？假设字段id是表t的主键。结果取决于事务A在执行完两条update语句后，持有哪些锁，以及在什么时候释放。 实际上事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行。因此事务A持有的两个记录的行锁，都是在commit的时候才释放的。 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。这样操作可以最大程度地减少事务之间的锁等待，提升并发度。 死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。如下图所示，事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。 出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。 在InnoDB中，innodb_lock_wait_timeout的默认值是50s，对于在线服务来说一般是无法接受的。但是不能把这个值设得很小，因为正常的锁等待也有可能被错误地释放。所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，但是每个新的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的，会消耗大量的CPU资源。 怎么解决由这种热点行更新，导致的死锁检测耗费大量CPU资源的问题呢？ 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是大部分业务设计时不会把死锁当做一个严重错误，遇到异常业务重试就完了，如果锁等待超时的话对业务来说是有损的。 控制并发度，在数据库服务端对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。如果数据库层面没有团队支持，可以考虑通过将一行改成逻辑上的多行来减少锁冲突。 🔥事务隔离级别的原理在第3章中曾经提到过，如果是可重复读隔离级别，事务T启动的时候会创建一个视图read-view，之后事务T执行期间，即使有其他事务修改了数据，事务T看到的仍然跟在启动时看到的一样。 但是，在第4章中，关于行锁的描述时又提到，一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？ 以如下这个表为例， 123456mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `k` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2); 关于事务的启动时机，begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用start transaction with consistent snapshot 这个命令。在本笔记中，如果没有特别说明，都是默认autocommit=1。 令人惊讶地，结果是事务B查到的k的值是3，而事务A查到的k的值是1，具体原因会在后面介绍。 在MySQL里，有两个“视图”的概念： 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view … ，而它的查询方法与表一样。 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现 🔥MVCC是如何提供“快照”的InnoDB里面每个事务有一个唯一的事务ID，叫作transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。 而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。 也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id。 如下图所示，就是一个记录被多个事务连续更新后的状态。 图中虚线框里是同一行数据的4个版本，当前最新版本是V4，k的值是22，它是被transaction id 为25的事务更新的，因此它的row trx_id也是25。 图中的三个虚线箭头，就是undo log；而V1、V2、V3并不是物理上真实存在的，而是每次需要的时候根据当前版本和undo log计算出来的。 那么InnoDB是怎么定义快照的？按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见 在实现上， InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。 数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。 而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。 这个视图数组把所有的row trx_id 分成了几种不同的情况。 这样，对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能： 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况 a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见； b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。 有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，生成的版本一定属于上面的2或者3(a)的情况，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。 所以你现在知道了，InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。 继续看一下图1中的三个事务，分析下事务A的语句返回的结果，为什么是k=1。 这里，我们不妨做如下假设： 事务A开始前，系统里面只有一个活跃事务ID是99； 事务A、B、C的版本号分别是100、101、102，且当前系统里只有这四个事务； 三个事务开始前，(1,1)这一行数据的row trx_id是90。 这样，事务A的视图数组就是[99,100], 事务B的视图数组是[99,100,101], 事务C的视图数组是[99,100,101,102]。 为了简化分析，我先把其他干扰语句去掉，只画出跟事务A查询逻辑有关的操作： 从图中可以看到，第一个有效更新是事务C，把数据从(1,1)改成了(1,2)。这时候，这个数据的最新版本的row trx_id是102，而90这个版本已经成为了历史版本。 第二个有效更新是事务B，把数据从(1,2)改成了(1,3)。这时候，这个数据的最新版本（即row trx_id）是101，而102又成为了历史版本。 你可能注意到了，在事务A查询的时候，其实事务B还没有提交，但是它生成的(1,3)这个版本已经变成当前版本了。但这个版本对事务A必须是不可见的，否则就变成脏读了。 好，现在事务A要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务A查询语句的读数据流程是这样的： 找到(1,3)的时候，判断出row trx_id=101，比高水位大，处于红色区域，不可见； 接着，找到上一个历史版本，一看row trx_id=102，比高水位大，处于红色区域，不可见； 再往前找，终于找到了(1,1)，它的row trx_id=90，比低水位小，处于绿色区域，可见。 这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。这个判断规则是从代码逻辑直接转译过来的，但是正如你所见，用于人肉分析可见性很麻烦。 所以翻译一下。一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。 对于可重复读的隔离级别，记住这个规则就可以来分析了。 🔥更新逻辑事务B的update语句，如果按照一致性读，好像结果不对？如下图，事务B的视图数组是先生成的，之后事务C才提交，不是应该看不见(1,2)吗，怎么能算出(1,3)来的？ 是的，如果事务B在更新之前查询一次数据，这个查询返回的k的值确实是1。但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务C的更新就丢失了。因此，事务B此时的set k=k+1是在（1,2）的基础上进行的操作。 所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。 因此，在更新的时候，当前读拿到的数据是(1,2)，更新后生成了新版本的数据(1,3)，这个新版本的row trx_id是101。 其实，除了update语句外，select语句如果加锁，也是当前读。所以，如果把事务A的查询语句select * from t where id=1修改一下，加上lock in share mode 或 for update，也都可以读到版本号是101的数据，返回的k的值是3。下面这两个select语句，就是分别加了读锁（S锁，共享锁）和写锁（X锁，排他锁）。 12select k from t where id=1 lock in share mode;select k from t where id=1 for update; 再进一步，假设事务C不是马上提交的，而是变成了下面的事务C’（如下右图所示），会怎么样呢？ 事务C’的不同是，更新后并没有马上提交，在它提交前，事务B的更新语句先发起了。前面说过了，虽然事务C’还没提交，但是(1,2)这个版本也已经生成了，并且是当前的最新版本。那么，事务B的更新语句会怎么处理呢？ 这时候，我们在上一篇文章中提到的“两阶段锁协议”就要上场了。事务C’没提交，也就是说(1,2)这个版本上的写锁还没释放。而事务B是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务C’释放这个锁，才能继续它的当前读。如下图所示 综上所述，事务的可重复读的能力是怎么实现的？ 可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。","link":"/2025/02/15/MySQL%E5%AE%9E%E6%88%9845%E8%AE%B2-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"title":"leetcode 31. 下一个排列","text":"https://leetcode.com/problems/next-permutation/description/ 31.下一个排列 整数数组的排列是将其成员排列成序列或线性顺序。 例如，对于arr = [1,2,3]，arr的所有排列如下：[1,2,3]，[1,3,2]，[2,1,3]，[2,3,1]，[3,1,2]，[3,2,1]。整数数组的下一个排列是它的整数下一个字典序排列。更正式地说，如果将数组的所有排列按字典序排序放入一个容器中，那么该数组的下一个排列就是排序容器中紧随其后的排列。如果无法进行这种排列，则数组必须重新排列为最低可能的顺序（即按升序排序）。 例如，arr = [1,2,3]的下一个排列是[1,3,2]。 同样，arr = [2,3,1]的下一个排列是[3,1,2]。 而arr = [3,2,1]的下一个排列是[1,2,3]，因为[3,2,1]没有字典序更大的排列。给定一个整数数组nums，找到nums的下一个排列。替换必须就地完成，并且只能使用常量额外内存。 示例 1：输入：nums = [1,2,3]输出：[1,3,2] 示例 2：输入：nums = [3,2,1]输出：[1,2,3] 示例 3：输入：nums = [1,1,5]输出：[1,5,1] 约束条件： 1 &lt;= nums.length &lt;= 100 0 &lt;= nums[i] &lt;= 100 解法关键点：考虑一种比较复杂的情况，如[2,3,5,4,1]，它的下一个排列是[2,4,1,3,5]。这种下一个排列是怎么出现的呢， 对于位置i来讲，在(i, n-1]的区间上如果存在位置j，使得最小的nums[j]满足nums[j]&gt;nums[i]，我们应该把它冒泡出来，换到i的位置上，在这个例子中就是把4换到3的位置上，集合变成[2,4,5,3,1]。即从右侧开始找到第一个升序对，交换位置。这样，一个较大的数就“晋升”上来了 寻找右侧开始的升序对时，不需要做O(n^2)的遍历，因为除了这个升序对之外其他都是降序的，所以我们可以做到O(2n)的时间复杂度，第一步只要找到比nums[i+1]小的数字nums[i]，nums[i]就是升序对的左侧值，再重新从数组nums右侧开始遍历，找到第一个比nums[i]大的nums[j]就可以了，j不一定等于i+1 接着我们只要把剩余的部分[i+1, n-1]做升序排序就可以了，这里面有一个优化可以避免直接O(log n)排序。当我们找到了位置j之后，有nums[i]&lt;nums[j]，对于j来讲有nums[i+1]&gt;...&gt;nums[j]...&gt;nums[n-1]，所以经过第1步的交换后的序列在[i+1, n-1]的区间上仍然是降序的，而我们只要用双指针从左右向中间夹，左右指针数值交换，就能把降序转升序了 对于[i+1, j-1]区间的x来讲，一定nums[i]&gt;nums[x]，不然第一步找出来的位置就不是j了， 对于[j+1, n-1]区间的y来讲，一定nums[i]&gt;nums[y]，不然第一步找出来的位置就不是j了， 1234567891011121314151617181920212223242526class Solution { public void nextPermutation(int[] nums) { int idx = -1; for (int i = nums.length - 2; i &gt;= 0; i--) { if (nums[i] &lt; nums[i + 1]) { idx = i; break; } } if (idx != -1) { for (int i = nums.length - 1; i &gt; idx; i--) { if (nums[i] &gt; nums[idx]) { int tmp = nums[idx]; nums[idx] = nums[i]; nums[i] = tmp; break; } } } for (int start = idx + 1, end = nums.length - 1; start &lt; end; start++, end--) { int tmp = nums[start]; nums[start] = nums[end]; nums[end] = tmp; } }}","link":"/2025/04/20/leetcode-31-%E4%B8%8B%E4%B8%80%E4%B8%AA%E6%8E%92%E5%88%97/"},{"title":"Spark原理和实践","text":"Spark概念Spark 是一个基于内存的大数据分布式计算框架RDD：Partition：Job：Task：Driver：Executor： Spark为什么比MapReduce执行更快 DAG 执行模型：Spark 将整个计算构建成一个有向无环图（DAG），可对多步算子进行统一调度和优化；MapReduce 则强制每个 Job 都是单一的 Map→Shuffle→Reduce，阶段之间无融合 算子融合（Pipelining）：对多个窄依赖算子（如 map、filter）进行链式执行，在同一个 Task 中完成，不产生中间写盘；MapReduce 每步都要落盘并重新调度 内存优先 + 本地磁盘优化：Spark 缓存中间数据到内存（或本地临时磁盘），shuffle 时只在必要时 spill；MapReduce 则把中间结果全部写到 HDFS，I/O 成本高 RDD、DataFrame 和 DatasetRDD：弹性分布式数据集，是Spark中最基本的数据处理模型。代码中是一个抽象类，它代表了一个弹性的、不可变的、可分区、里面的元素可进行计算的集合。RDD封装了计算逻辑，并不保存数据 - 不可变 - 分区化 - 有容错机制（Lineage） - 惰性求值 - 分布式计算DataFrame：结构化数据，类似关系型数据库表，支持 Catalyst 优化器，性能好但不类型安全Dataset：结合 RDD 的类型安全和 DataFrame 的性能优化，Scala 和 Java 支持较好。特别的，DataFrame=DataSet[Row] 算子Transformation：从现有的数据集创建一个新的数据集，返回一个新的 RDD 操作。Transformation都是惰性的，它们并不会立刻执行，只是记住了这些应用到 RDD 上的转换动作Action：触发在 RDD 上的计算，这些计算可以是向应用程序返回结果，也可以是向存储系统保存数据常见的 Transformation 包括：map、mapVaules、filter、flatMap、mapPartitions、uoin、join、distinct、xxxByKey常见的 Action 包括：count、collect、collectAsMap、first、reduce、fold、aggregate、saveAsTextFile 宽依赖 &amp; 窄依赖广播变量 &amp; 累加器缓存 &amp; checkpoint数据本地化GROUP BY、SORT BY、DISTRIBUTE BY、CLUSTER BY 区别是什么？ 语法 用途 是否 Shuffle 是否排序 分区行为 GROUP BY 分组聚合（如 sum、count） ✅ 是 ❌ 否 相同 key 会到同一分区 SORT BY 分区内排序（非全局） ❌ 否 ✅ 是 保持原分区 DISTRIBUTE BY 控制数据如何分区（打散数据） ✅ 是 ❌ 否 同 key 到同一分区 CLUSTER BY 等于SORT BY + DISTRIBUTE BY，排序写入、建索引、聚簇优化，如写入parquet ✅ 是 ✅ 是 等价于 DISTRIBUTE + SORT Spark On Yarn提交流程Shuffle介绍Hash-based shuffle 机制： 普通运行机制：设下游stage的task数量为n，上游stage的shuffle write阶段每个map task，都会生成n个临时文件。下游shuffle read阶段每个task从上有的所有task所在节点，拉取自己所需要的临时文件，每次都拉取鱼自己buffer缓冲区相同大小的数据，然后通过内存中的Map数据结构进行聚合等操作。以此类推，直到最后所有数据都拉取处理完 优化后的运行机制：增加参数spark.shuffle.consolidateFiles参数，默认值为false。开启后会开启consolidate机制，每个并行度（core）会创建一个shuffleFileGroup，每个group会产生下游task数量的临时文件，在同一个executor的core上执行的task会复用临时文件，可以极大减少临时文件数量。shuffle read时根据共享临时文件中offset读取 总结： 优点： 可以省略不必要的排序开销 避免了排序所需的内存开销 缺点： 生产的文件过多，会对文件系统造成压力 大量的小文件的随机读写带来一定磁盘开销 数据块写入时所需的缓存空间也会随之增加，对内存造成压力 即使是consolidate机制，在reduce task数量过多的情况下，文件也很多 Sorted-based shuffle 机制： 普通运行机制：shuffle write的每个task将数据写入内存数据结构，数据结构中的数据量达到阈值（默认10000）之后，将数据排序写入磁盘临时文件，最后将一个task的所有spill溢写磁盘临时文件合并，每个map task写入一个磁盘和一个索引文件。排序是为了把所有属于同一个partition的数据放在一起，以便写入磁盘时合并连续数据段，shuffle read可以执行offfset拉取，不需要加载整个文件。 bypass运行机制：reduce任务数量比较少的情况，hash-based shuffle会比sorted-based shuffle效率更高。当满足如下条件时，会进行hash，根据hash值通过缓冲写入对应的磁盘文件，省去排序的过程，最后会对每个task产生的所有临时磁盘文件做合并，每个task生成一个磁盘文件，和一个索引文件 shuffle read task的数量小于阈值spark.shuffle.sort.bypassMergeThreshold 使用的算子没有map-side的聚合行为，比如reduceByKey Tungsten Sorted运行机制：对sort的优化，排序的不是内容本身，是内容序列化之后的指针（元数据），基于序列化之后的二进制数据操作，没有了序列化和反序列化的过程，内存消耗降低。使用的是堆外内存操作，gc开销减少。使用T-S机制的前提比较苛刻，具体如下 shuffle依赖中不带聚合操作或者对输出进行排序的要求 shuffle的序列化器支持序列化值的重定位（仅支持Kryo Serialized） shuffle过程中的输出分区个数少于16777216个 Remote ShuffleShuffle存在的问题 磁盘随机读写严重：离线数据量增长，一定会增加分区数量来增大并发，因此shuffle文件会以mapper*reducer平方关系增加。单个shuffler文件大概是几k，几十k的样子。磁盘随机读写非常严重 shuffle read负载不均衡：请求的多个container分布在同一台机器上时，reduce时会请求多次 数据无备份：shuffle文件存储在mapper所在本地磁盘，磁盘故障或者宕机会导致无法读取 Remote Shuffle serviceRSS过程： mapper端数据不落盘，按照reducer划分，push到对应的rss内存中 rss内存中merge不同mapper发过来的数据，写到分布式存储中 reducer直接去分布式存储中读取已经merge好的shuffle数据优化点： 减少随机读：按照reducer组织数据，每个文件只归属于一个reducer，reducer读取变成顺序读 负载均衡：通过rss和hdfs来实现shuffle read负载均衡 数据多备份：分布式存储shuffle文件多备份，提高可用性 Push-based shufflesorted-based shuffle的增强。mapper端结束后主动将数据推送给reduce节点，避免reduce拉取。与rss的区别是，rss写的是外部存储，pss写的是reduce节点，交由reduce节点的ess来管理。但是shuffle数据推送过去之后，如果executor被回收或者宕机，那么数据会丢失不可用。任务规模越大、时间越长，发生executor丢失的概率越高，Push-based Shuffle风险越大，所以PSS更适合中等规模的任务。 Q：什么是ess？External shuffle serviceA：背景：1. 在动态资源申请机制下，executor被移除之后仍然需要保留其上运行的任务结果状态 2.对于shuffle而言，map task溢写的临时文件定义：运行在集群中每一个节点上的常驻进程，独立于Spark application和executor存在，开启这个服务之后，executor会从这个服务拉取shuffle文件，而不是从上游executor拉取。即executor终止之后，状态依然是可用的 不同类型shuffle对比 维度/类型 Hash Shuffle Sort-based Shuffle Push-based Shuffle (Spark 3.1+) Remote Shuffle (RSS、Uniffle 等) 是否默认启用 否（已废弃） ✅ 是（Spark 默认 Shuffle 类型） 否（需配置启用） 否（需接入插件） 数据写入方式 每个下游 partition 写一个临时文件 将所有输出排序后写一个文件 + 索引 Map 端主动推送数据至 Reduce 端 Map 端写入远程 Shuffle 服务 文件数量 多（Map端每个任务 × Reduce数） 少（一个任务一个输出文件 + index） 少（推到 Reduce 本地） 可控，由服务端统一管理 是否排序 ❌ 否 ✅ 是 ✅ 是（基于 Sort Shuffle） 取决于服务配置（一般是支持排序的） 性能表现 较快但容易产生大量小文件 稍慢但更稳定 性能好，减少 Reduce 拉取等待 性能稳定，容错强 容错能力 差，executor 丢失后数据丢 差，executor 丢失后 Reduce 会失败 较差（数据存在 Reduce 节点） ✅ 强，数据在远程独立服务中 是否支持动态资源释放 ❌ 否（数据存在 executor） ❌ 否 ❌ 否（数据存在 Reduce 节点） ✅ 支持（Executor 可动态释放） 是否需要外部服务 ❌ 否 ❌ 否 ❌ 否 ✅ 是（部署 Shuffle Server） 推荐使用场景 旧版本 Spark，小任务 ✅ 默认通用型 Shuffle 中等规模任务，想减少 Reduce 阶段等待 大规模作业、Spark on K8s、动态资源分配场景 是否支持 Combine ✅ 是 ✅ 是 ✅ 是 ✅ 是（服务端支持） 是否支持 Spark on K8s 不推荐 ✅ 支持 ✅ 支持 ✅ 推荐","link":"/2025/05/13/Spark%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E8%B7%B5/"},{"title":"leetcode 33.在旋转排序数组中搜索","text":"https://leetcode.com/problems/search-in-rotated-sorted-array/description/ 33.旋转有序数组中的搜索[中等] 有一个整数数组nums，按升序排序（值各不相同）。在传递给您的函数之前，nums可能被一个未知的枢轴索引k（1 &lt;= k &lt; nums.length）旋转，使得得到的数组为[nums[k], nums[k+1], …, nums[n-1], nums[0], nums[1], …, nums[k-1]]（索引从0开始）。例如，[0,1,2,4,5,6,7]可能在枢轴索引3处旋转并变为[4,5,6,7,0,1,2]。给定可能的旋转后的数组nums和一个整数target，如果target在nums中，则返回target的索引，如果不在nums中，则返回-1。必须编写一个具有O(logn)时间复杂度的算法。 示例1：输入：nums = [4,5,6,7,0,1,2], target = 0输出：4 示例2：输入：nums = [4,5,6,7,0,1,2], target = 3输出：-1 示例3：输入：nums = [1], target = 0输出：-1 约束条件： 1 &lt;= nums.length &lt;= 5000 -10^4 &lt;= nums[i] &lt;= 10^4 nums的所有值都是唯一的。 nums是一个可能旋转的升序数组。 -10^4 &lt;= target &lt;= 10^4 解法关键点： 只有在递增区间内，且数字大小在左右边界大小之内才能够收敛区间 当[start, end]为递增区间时，只判断target和单边的关系，无法确定target是否在此区间，必须判断双边关系才能锁定target在此区间 当[start, end]为非单调增区间时，则其中可能包含任何大小的数字，比start大或者小，比end大或者小都有可能，无法收敛 指定mid的位置之后，左右两部分可能都是递增序列，而不是递增+旋转递增的序列组合 可能存在(start+end)/2=start的情况，所以必须用+1或-1进行收敛 尝试收敛时，nums[mid] &lt; target &amp;&amp; target &lt;= nums[end]为真时，nums[mid]和target一定不等，所以start可以被置为mid+1；为假时可以判断target在[start, mid]区间内，结合上面nums[mid] == target为假的条件，可以判断target如果存在则一定在[start, mid-1]区间内 12345678910111213141516171819202122232425class Solution { public int search(int[] nums, int target) { int start = 0, end = nums.length - 1; while (start &lt;= end) { int mid = (start + end) &gt;&gt; 1; if (nums[mid] == target) { return mid; } if (nums[mid] &lt;= nums[end]) { if (nums[mid] &lt; target &amp;&amp; target &lt;= nums[end]) { start = mid + 1; } else { end = mid - 1; } } else { if (nums[start] &lt;= target &amp;&amp; target &lt; nums[mid]) { end = mid - 1; } else { start = mid + 1; } } } return -1; }}","link":"/2025/04/19/leetcode-33-%E5%9C%A8%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E6%90%9C%E7%B4%A2/"},{"title":"pyspark分布式训练","text":"","link":"/2022/07/03/pyspark%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"title":"Redis原理和实践","text":"数据结构整体组织形式全局哈希表，每个哈希桶存储键值对，值存储的是指向实际元素的指针。redis采用链地址法（拉链法）解决哈希冲突，当链表长度过长时查询速度会变慢，所以链表长度过长时需要rehash，增加哈希桶数量 rehash过程： 使用两个全局哈希表实现 给哈希表2分配更大的空间，比如哈希表1的两倍 把哈希表1的数据重新映射拷贝到哈希表2 释放哈希表1的空间 渐进式rehash： 时机：负载因子（哈希表已保存的节点数量/哈希表大小）大于1且没有进行bgsave或bgrewiteaof时。或者负载因子大于5时 原因：第2步涉及大量数据拷贝，如果一次性把哈希表1的数据迁移完，会造成Redis线程阻塞无法响应其他请求 方法：在第2步操作时，Redis仍然接受请求，每处理一个请求时，从哈希表1的第一个索引位置开始顺带着将索引位置上的所有entries拷贝到哈希表2中，这样把一次性大量拷贝的开销分摊到多次处理请求的过程中。在渐进式rehash进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。新增kv的时候会被保存到哈希表2中，哈希表1不再进行添加动作 元素数据结构 String 底层数据结构： 简单动态字符串 SDS List 底层数据结构：双向链表（3.2以后已经废弃）、压缩列表（3.2以后已经废弃）；quicklist Hash 底层数据结构：压缩列表（后面换成listpack）、哈希表 Sorted Set 底层数据结构：压缩列表（后面换成listpack）、跳表 Set 底层数据结构：哈希表、整数数组 数据结构介绍 **简单动态字符串(SDS)**：二进制存储，记录了长度，获取长度的时间复杂度为O(1)，不会发生缓冲区溢出，节省内存空间 压缩列表：类似数组，表头多了zlbytes、ztail、zlen是那个字段，分别表示列表长度、列表尾偏移量和列表中entry个数，表尾多了个zlend字段表示列表结束。定位第一个和最后一个元素可以通过表头字段确定，时间复杂度O(1)，查找其他元素时间复杂度O(n) 跳表：在链表基础上增加了多级索引，通过索引位置的跳转实现快速定位元素。时间复杂度O(logN) 压缩列表的缺陷是，新增某个元素或修改某个元素时，如果空间不不够需要重新分配，如果插入对象较大，后续元素结构都需要变更 Q：为什么不用平衡树、红黑树或者B+树？A：平衡树和红黑树需要在加入删除元素之后调整树结构，需要额外的成本；B+树主要解决磁盘IO问题，内存随机读写效率很高 线程模型单线程处理，基于epoll的多路复用，可以同时监听多个套接字 Q：Redis操作为什么这么快？ A：如下 纯内存存储，读写微妙级 单线程+非阻塞I/O，基于epoll的Reactor模式，避免多线程切换和锁竞争，高并发下性能问题 高效数据结构 持久化机制异步进行，不阻塞住线程 网络开销小，RESP协议，序列化/反序列化开销小，支持pipeline操作 TODO：redis 6.0之后为什么引入多线程 持久化AOFAppend Only File，写后日志，先执行命令写数据再记录日志（由主线程操作）。Redis为避免额外检查开销，向AOF日志中记录日志时不会做语法检查，所以是写后日志，保证写入的都是正确的命令。 AOF模式下面临的挑战： 执行完命令写入日志之前宕机，数据会丢掉 日志写入不会阻塞当前操作，但是会阻塞下一个操作 写回策略 Always：同步写回，每个写命令执行完，立马同步将日志写回磁盘 Everysec：每秒写回，每个写命令执行完，只是先把日志孩子写到AOF文件的内存缓冲区，每隔1秒将缓冲区刷回磁盘 No：操作系统控制写回，每个写命令执行完，只是先把日志孩子写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区刷回磁盘 越往下性能越好，宕机时丢数据越严重 AOF重写 原因：每条命令都记录会导致AOF文件很大，恢复也会很慢，所以需要对一个key的多个操作合并，保证最后一次操作后的状态就可以了 方法：fork子进程，合并重写AOF文件。主线程双写AOF缓冲，AOF重写缓冲，这样切换AOF文件时，AOF重写缓冲中包含了重写期间的所有操作，不会丢失变更 RDB内存快照，将内存中的数据在某一刻的状态记录在文件中，用于恢复 生成RDB文件的两个命令 save：在主线程中执行，会导致阻塞 bgsave：创建子进程用于写入RDB文件，避免主线程阻塞（默认配置） bgsave如何保证不阻塞读写操作 不阻塞读：bgsave的fork子进程，因而主线程不阻塞，可以继续处理读请求 不阻塞写：写时复制技术（COW，Copy-On-Write），Fork出的子进程可以共享主进程的所有内存数据，主进程在修改某份数据时会产生新的副本进行修改。因此bgsave子进程可以将原本的数据尽数写入RDB文件。这样主进程仍然可以修改数据，不阻塞 Q：bgsave频率设置可以高一些吗？ A：不能太频繁，1、会占用很多磁盘IO；2、fork动作会阻塞主线程 AOF&amp;RDB混合RDB文件恢复快速，但是两次快照期间的数据会丢失 AOF简单数据丢失概率小，但是需要顺序重新执行所有命令 AOF&amp;RDB混合，RDB以一定的频率执行，在两次RDB之间用AOF记录所有命令操作，这样丢失概率低的同时恢复也很快 网络框架主从复制三种模式：全量复制、基于长连接的命令传播、增量复制 redis的模式是主节点负责读写，从节点负责读 首次同步（使用全量复制） 从库发送psync命令告知主库即将进行同步，主库回复FULLRESYNC命令告诉从库要进行同步，告知runnID和复制offset 主库将所有数据同步给从库，发送RDB文件，从库进行RDB文件加载 主库将第2阶段中新到的写命令发送给从库，补全变更 “主-从-从”及联模式可以减少主库fork子进程进行bgsave的压力 长连接命令传播 复用首次同步长连接进行命令的同步 主从库网络断连 2.8之前断连需要重新全量复制，2.8之后可以进行增量复制继续同步 写入replication_buffer的同时写入repl_backlog_buffer环形缓冲，只同步从库offset和主库offert之间的数据 哨兵机制哨兵进程使用PING命令检测自己和主从库的连接情况，用来判断实例的状态。 主观下线：如果发现对主库或从库的PING超时了，可以将其标记为主观下线。 客观下线：对主库的主动下线标记不能直接开启主从切换，存在网络波动的可能，需要哨兵集群中大于等于n+1/2的实例判定主库为主观下线，主库才能标记为客观下线，进行主从切换的流程 升为主库的从库选择 首先需要满足主从库断连的最大超时时间，发生次数不超过10次，即网络良好的从库才能被选中 其次应该遵循以下轮次进行选择 库优先级高的 从库复制进度快的 从库ID号小的 哨兵集群的建立 基于pub/sub机制在主库上同一个频道发布消息，建立连接，形成哨兵集群。通过info命令获取从库连接信息，和从库建立连接并监控。 数据分片Redis-Cluster 按照slot划分 缓存一致性 Cache-Aside 旁路缓存 方式：缓存位于一边，应用程序直接与缓存和数据库交互。读缓存，不存在时从数据库读取。写数据库删缓存 Q&amp;A： Q：为什么是删除而不是更新？ A：删除是一个最终一致性的行为，更新不是 Q：写数据时为什么不是先删缓存再更新数据库？在这种方案上有进一步解决办法吗？ A：因为写的同时可能有读请求，读请求可能会把未更新的旧数据又写回来。有的，写的流程改为：删缓存→更新数据库→sleep→删缓存（延迟双删） Q：读写并行时，读到数据库旧数据，写数据库新数据，写删除缓存数据，读更新缓存为旧的数据怎么办？ A：两种方式可选，1、消息队列异步重试；2、订阅binlog、再操作缓存 Q：对缓存命中率要求比较高，更新数据库 Read-Through 方式：缓存与数据库保持一致，当缓存未命中时，它会从数据库中加载丢失的数据，填充缓存并将其返回给应用程序 与Cache-Aside的区别： Cache-Aside中，应用程序负责从数据库获取数据并填充缓存，但是在Read-Through中，这个逻辑通常由组件库或独立缓存提供支持 与Cache-Aside不同，Read-Through中的数据模型不能与数据库不同 Write-Through 方式：数据首先写入缓存，然后写入数据库。缓存与数据库串联，写入总是通过缓存到主数据库。这种模式本身没有太大的作用，甚至还会引入额外的写入延迟，因为数据总是先写入缓存，然后写入数据库。但是在与Read-Through配合使用之后，就可以获得数据一致性的保证 Write-Around 方式：数据直接写入数据库，只有读取的数据才能进入缓存。可以结合Read-Through使用，在读频率较低的场景下性能较好 Write-Back(Write-Behind) 方式：应用程序将数据写入缓存，写入后立即确认，并在延迟一段时间后将数据写回数据库 TODO 本地缓存和分布式缓存区别？多级缓存？应用场景？","link":"/2025/05/06/Redis%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E8%B7%B5/"},{"title":"分布式事务一致性","text":"分布式事务问题定义：分库架构下无法使用单机数据库的事务能力，需要在多个服务协同操作下保证数据一致性 解决方案：强一致性协议一个协调者，多个参与者，协同进行分布式事务处理 2PC（两阶段提交）流程 准备阶段：协调者向各个参与者发起询问，说要执行一个事务，各参与者可能回复YES、NO或超时。 提交阶段：如果所有参与者都回复的是 YES，则事务协调者向所有参与者发起事务提交操作，即Commit操作，所有参与者各自执行事务，然后发送ACK 特点优点原理简单，实现方便 缺点 同步阻塞：在阶段1，锁定资源之后，要等所有节点返回，然后才能一起进入阶段2，不能很好地应对高并发场景 单点问题：阶段1完成之后，如果在阶段2事务协调者宕机，则所有的参与者接收不到Commit或Rollback指令，将处于“悬而不决”状态 数据不一致：网络或者协调者出现问题，部分参与者收到commit请求进行提交，剩下的则没有提交 3PC（三阶段提交）2PC的改进版，其将二阶段提交协议的“提交事务请求”过程一分为二，形成了由CanCommit、PreCommit和do Commit三个阶段组成的事务处理协议 流程 CanCommit：协调者向各个参与者发起询问，说要执行一个事务，各参与者可能回复YES、NO或超时。CanCommit阶段参与者发现超时会回滚 PreCommit：如果协调者收到的都是YES，则向参与者发送PreCommit请求，参与者执行预提交，并反馈给协调者ACK响应（commit或者abort）。如果有一个是NO，则向所有参与者提交abort请求。PreCommit阶段参与者发现超时会提交 doCommit：协调者发送请求，让参与者进行提交或者回滚。如果协调者或网络出现故障，参与者收不到指令会继续进行提交 特点优点降低了参与者的阻塞范围，并且能够在出现单点故障后继续达成一致 缺点参与者收到PreCommit之后，如果发生网络故障，协调者发送的，可能出现一部分提交一部分回滚的情况，即数据不一致 2PC vs 3PC Q：引入 PreCommit 的作用是什么？A： 明确状态：避免歧义，所有参与者收到 pre-commit 后，进入一个明确的中间状态（已准备提交但尚未提交）。如果此时协调者宕机，参与者就知道协调者已经决定提交了，只是还没发出最终指令 非阻塞：所有阶段都有超时机制，避免了像 2PC 那样“等死”的情况，即使协调者崩溃，参与者也不会一直阻塞。 特性 2PC（Two-Phase Commit） 3PC（Three-Phase Commit） 阶段数 2（Prepare + Commit） 3（CanCommit + PreCommit + DoCommit） 是否阻塞 是（参与者会阻塞等待协调者） 否（超时后可自行决定） 容错性 低（协调者崩溃会导致阻塞） 较高（通过超时和中间状态降低阻塞） 数据一致性 强一致 强一致（但牺牲一定性能） 复杂度 低 高 是否存在协调者单点风险 是 是（仍需解决） 解决方案：最终一致性一般的思路是通过消息中间件来实现“最终一致性”。系统A收到用户的转账请求，系统A先自己扣钱，也就是更新DB1；然后通过消息中间件给系统B发送一条加钱的消息，系统B收到此消息，对自己的账号进行加钱，也就是更新DB2。但是这里在系统A操作时，需要更新DB1并发送消息，这里面存在一个技术问题 如果是先发消息后改DB，可能会发生消息发送成功DB修改失败，即DB1扣钱失败DB2加钱成功 如果是先改DB后发消息，可能会发生DB修改成功但是消息发送失败，即DB1扣钱成功DB2加钱失败上述两种情况都是不符合预期的，有人说可以将发送mafka消息和更新DB1的操作放到一个事务里面，这样看似是ok的但实际上是有问题的 发送消息失败无法判断是消息中间件没有收到消息，还是返回响应的时候失败 把网络调用放在数据库事务里面，可能会因为网络的延时导致数据库长事务，严重的会阻塞整个数据库 基于业务架构设计实现 系统A增加一张消息表，系统A不再直接给消息中间件发送消息，而是把消息写入到这张消息表中。把DB1的扣钱操作（表1）和写入消息表（表2）这两个操作放在一个数据库事务里，保证两者的原子性 系统A准备一个后台程序，源源不断地把消息表中的消息传送给消息中间件。如果失败了，也不断尝试重传。保证消息至少传递一次 系统B消费消息队列中的消息，做DB2的数据操作 消息丢失问题：如果处理到一半宕机则消息可能会丢失，所以需要消费完再ack，但这样可能会导致重复消费 消息重复问题：增加判重表，记录处理过的消息，这样就能实现幂等。或者业务逻辑可以判重也可以 基于消息队列事务实现RocketMQ有事务消息的概念。RocketMQ不是提供一个单一的“发送”接又，而是把消息的发送拆成了两个阶段，Prepare阶段(消息预发送)和Confirm阶段(确认发送)。 系统A调用Prepare接又，预发送消息。此时消息保存在消息中间件里，但消息中间件不会把消息给消费方消费，消息只是暂存在那。 系统A更新数据库，进行扣钱操作。 步骤3:系统A调用Comfirm接又，确认发送消息。此时消息中间件才会把消息给消费方进行消费这里有两种异常场景， 步骤1、2成功，3失败或者超时 步骤1成功，步骤2失败或者超时。步骤3不会执行这些问题可以通过RocketMQ的机制实现，RocketMQ会定期(默认是1min)扫描所有的预发送但还没有确认的消息，回调给发送方，询问这条消息是要发出去，还是取消。发送方可以自行根据业务状态回复 TCC事务状态表+调用方重试+接收方幂等对账","link":"/2025/05/04/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B8%80%E8%87%B4%E6%80%A7/"},{"title":"leetcode 45.跳跃游戏II","text":"https://leetcode.com/problems/jump-game-ii/ 45.跳跃游戏 II 你被给了一个长度为 n 的整数数组 nums，索引从 0 开始。你最初位于 nums[0]。数组中的每个元素 nums[i] 代表从索引 i 出发的最大向前跳跃长度。换句话说，如果你在 nums[i]，你可以跳到任何 nums[i + j]，其中： 0 &lt;= j &lt;= nums[i] 且 i + j &lt; n返回到达 nums[n - 1] 的最小跳跃次数。测试用例生成保证你可以到达 nums[n - 1]。 示例 1：输入：nums = [2,3,1,1,4]输出：2解释：到达最后一个索引的最小跳跃次数是 2。从索引 0 跳 1 步到 1，然后跳 3 步到达最后一个索引。 示例 2：输入：nums = [2,3,0,1,4]输出：2 约束条件： 1 &lt;= nums.length &lt;= 10^4 0 &lt;= nums[i] &lt;= 1000 保证你可以到达 nums[n - 1]。 动态规划算法创建一个用于存储状态的数组minStepNums，用于存储位置i跳到最后位置所需的最小步数minStepNums[i]，对i位置来说可以到达的位置是(i, i+nums[i]]，假设里面的位置j具备最小的minStepNums[j]，则对于i位置来说到达最后位置所需的最小步数为minStepNums[i]=minStepNums[j]+1时间复杂度：O(n^2) 1234567891011121314151617class Solution { public int jump(int[] nums) { int[] minStepNums = new int[nums.length]; Arrays.fill(minStepNums, Integer.MAX_VALUE); // 初始化为最大值 minStepNums[nums.length - 1] = 0; for (int i = nums.length - 2; i &gt;= 0; i--) { int minStepNum = Integer.MAX_VALUE; for (int j = i + 1; j &lt;= i + nums[i] &amp;&amp; j &lt; nums.length; j++) { if (minStepNums[j] != Integer.MAX_VALUE) { // 为了防止溢出 minStepNum = Math.min(minStepNum, minStepNums[j] + 1); } } minStepNums[i] = minStepNum; } return minStepNums[0]; }} 贪心算法记录跳跃次数steps的同时，记录当前跳跃次数可到的的最远位置currentMaxPos，一边移动当前位置，一边判断情况 已经到达当前steps可到达的最远距离currentMaxPos，此时不得不跳跃一次，同时刷新currentMaxPos currentMaxPos的刷新：已经走过的位置可以根据每个位置的最大跳远距离，计算出下一次跳跃的最远距离nextMaxPos，跳完之后用这个值刷新currentMaxPos就可以了 还没到达currentMaxPos，可以跳可以不跳，但是不跳肯定是次数最少的123456789101112131415class Solution { public int jump(int[] nums) { int steps = 0; int currentMaxPos = 0; int nextMaxPos = 0; for (int i = 0; i &lt; nums.length - 1; i++) { nextMaxPos = Math.max(i + nums[i], nextMaxPos); if (i == currentMaxPos) { steps++; currentMaxPos = nextMaxPos; } } return steps; }} Q：加深一下，如果题目没有保证最后的位置一定可达，那怎么办？A：移动i之后先做i &gt; currentMaxPos的判断，如果大于了，说明无法到达此位置，直接返回-1就可以了","link":"/2025/04/27/leetcode-45-%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8FII/"},{"title":"创建第一个Akka应用","text":"关于本文 版本：2.6之后的版本为收费版本，2.6版本的scala版使用文档见v2.6使用文档，flink在用的也是这个版本 api类型：classic比较灵活，试用一下classic版本的api 构建应用Demo配置如下的pom文件 pom.xml >folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;tech.bravoqq&lt;/groupId&gt; &lt;artifactId&gt;demo-akka&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;scala.version&gt;2.12.19&lt;/scala.version&gt; &lt;scala.base.version&gt;2.12&lt;/scala.base.version&gt; &lt;akka.version&gt;2.6.21&lt;/akka.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt; &lt;artifactId&gt;akka-actor_${scala.base.version}&lt;/artifactId&gt; &lt;version&gt;${akka.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt; &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt; &lt;version&gt;4.9.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;scalaVersion&gt;${scala.version}&lt;/scalaVersion&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 官方demo给到的是一个ping-pong的系统，如下， Application.scala12345678910111213141516171819202122232425262728293031323334353637383940414243444546import akka.actor.{Actor, ActorRef, ActorSystem, PoisonPill, Props}import language.postfixOpsimport scala.concurrent.duration._case object Pingcase object Pongclass Pinger extends Actor { var countDown = 100 def receive = { case Pong =&gt; println(s&quot;${self.path} received pong, count down $countDown&quot;) if (countDown &gt; 0) { countDown -= 1 sender() ! Ping } else { sender() ! PoisonPill self ! PoisonPill } }}class Ponger(pinger: ActorRef) extends Actor { def receive = { case Ping =&gt; println(s&quot;${self.path} received ping&quot;) pinger ! Pong }}object Application extends App { val system = ActorSystem(&quot;pingpong&quot;) val pinger = system.actorOf(Props[Pinger](), &quot;pinger&quot;) val ponger = system.actorOf(Props(classOf[Ponger], pinger), &quot;ponger&quot;) import system.dispatcher system.scheduler.scheduleOnce(500 millis) { ponger ! Ping }}","link":"/2024/08/07/%E5%88%9B%E5%BB%BA%E7%AC%AC%E4%B8%80%E4%B8%AAAkka%E5%BA%94%E7%94%A8/"},{"title":"回溯相关题目整理","text":"原则: 回溯函数需要path、ans参数 允许包含重复数字，则处理前一定要先排序 只有全排列需要记录used[i]，因为需要区分重复的元素 Generate Parentheses 括号生成数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。 示例 1：输入：n = 3输出：[“((()))”,”(()())”,”(())()”,”()(())”,”()()()”] 示例 2：输入：n = 1输出：[“()”] 提示： 1 &lt;= n &lt;= 8 1234567891011121314151617181920212223class Solution { public List&lt;String&gt; generateParenthesis(int n) { List&lt;String&gt; ans = new ArrayList&lt;&gt;(); backtrack(n, 0, 0, new StringBuilder(), ans); return ans; } public void backtrack(int n, int left, int right, StringBuilder path, List&lt;String&gt; ans) { if (left == right &amp;&amp; left == n) { ans.add(path.toString()); } if (left &lt; n) { path.append('('); backtrack(n, left + 1, right, path, ans); path.deleteCharAt(path.length() - 1); } if (left &gt; right) { path.append(')'); backtrack(n, left, right + 1, path, ans); path.deleteCharAt(path.length() - 1); } }} Subsets 子集给你一个整数数组 nums ，数组中的元素 互不相同 。返回该数组所有可能的子集（幂集）。解集 不能 包含重复的子集。你可以按 任意顺序 返回解集。 示例 1：输入：nums = [1,2,3]输出：[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]] 示例 2：输入：nums = [0]输出：[[],[0]] 提示： 1 &lt;= nums.length &lt;= 10 -10 &lt;= nums[i] &lt;= 10 nums 中的所有元素 互不相同 1234567891011121314151617class Solution { public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) { List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); backtrack(nums, 0, new ArrayList&lt;&gt;(), ans); return ans; } private void backtrack(int[] nums, int start, List&lt;Integer&gt; path, List&lt;List&lt;Integer&gt;&gt; ans) { ans.add(new ArrayList&lt;&gt;(path)); for (int i = start; i &lt; nums.length; i++) { path.add(nums[i]); backtrack(nums, i + 1, path, ans); path.remove(path.size() - 1); } }} Subsets II 子集 II给你一个整数数组 nums ，其中可能包含重复元素，请你返回该数组所有可能的子集（幂集）。解集 不能 包含重复的子集。返回的解集中，子集可以按 任意顺序 排列。 示例 1：输入：nums = [1,2,2]输出：[[],[1],[1,2],[1,2,2],[2],[2,2]] 示例 2：输入：nums = [0]输出：[[],[0]] 提示： 1 &lt;= nums.length &lt;= 10 -10 &lt;= nums[i] &lt;= 10 12345678910111213141516171819202122class Solution { public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) { List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); Arrays.sort(nums); // ⭐ 排序是关键！ backtrack(nums, 0, new ArrayList&lt;&gt;(), ans); return ans; } private void backtrack(int[] nums, int start, List&lt;Integer&gt; path, List&lt;List&lt;Integer&gt;&gt; ans) { ans.add(new ArrayList&lt;&gt;(path)); for (int i = start; i &lt; nums.length; i++) { // ⭐ 跳过“同层”重复元素（核心去重逻辑） if (i &gt; start &amp;&amp; nums[i] == nums[i - 1]) { continue; } path.add(nums[i]); backtrack(nums, i + 1, path, ans); path.remove(path.size() - 1); } }} Permutations 全排列给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。 示例 1：输入：nums = [1,2,3]输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] 示例 2：输入：nums = [0,1]输出：[[0,1],[1,0]] 示例 3：输入：nums = [1]输出：[[1]] 提示： 1 &lt;= nums.length &lt;= 6 -10 &lt;= nums[i] &lt;= 10 nums 中的所有整数互不相同 12345678910111213141516171819202122class Solution { public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) { List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); backtrack(nums, ans, new ArrayList&lt;&gt;()); return ans; } private void backtrack(int[] nums, List&lt;List&lt;Integer&gt;&gt; ans, List&lt;Integer&gt; path) { if (path.size() == nums.length) { ans.add(new ArrayList&lt;&gt;(path)); return; } for (int i = 0; i &lt; nums.length; i++) { if (path.contains(nums[i])) { continue; } path.add(nums[i]); backtrack(nums, ans, path); path.remove(path.size() - 1); } }} Permutations II 全排列 II给定一个可包含重复数字的序列 nums ， 按任意顺序 返回所有不重复的全排列。 示例 1：输入：nums = [1,1,2]输出：[[1,1,2],[1,2,1],[2,1,1]] 示例 2：输入：nums = [1,2,3]输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] 提示： 1 &lt;= nums.length &lt;= 8 -10 &lt;= nums[i] &lt;= 101234567891011121314151617181920212223242526class Solution { public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) { List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); Arrays.sort(nums); backtrack(nums, ans, new ArrayList&lt;&gt;(), new boolean[nums.length]); return ans; } private void backtrack(int[] nums, List&lt;List&lt;Integer&gt;&gt; ans, List&lt;Integer&gt; path, boolean[] used) { if (nums.length == path.size()) { ans.add(new ArrayList&lt;&gt;(path)); } for (int i = 0; i &lt; nums.length; i++) { // 已经使用过的元素 // 同一层相同元素，只使用第一个 if (used[i] || (i &gt; 0 &amp;&amp; used[i - 1] == false &amp;&amp; nums[i] == nums[i - 1])) { continue; } used[i] = true; path.add(nums[i]); backtrack(nums, ans, path, used); used[i] = false; path.remove(path.size() - 1); } }} Combination Sum 组合总和给你一个 无重复元素 的整数数组 candidates 和一个目标整数 target ，找出 candidates 中可以使数字和为目标数 target 的 所有 不同组合 ，并以列表形式返回。你可以按任意顺序返回这些组合。candidates 中的 同一个 数字可以 无限制重复被选取 。如果至少一个数字的被选数量不同，则两种组合是不同的。对于给定的输入，保证和为 target 的不同组合数少于 150 个。 示例 1：输入：candidates = [2,3,6,7], target = 7输出：[[2,2,3],[7]]解释：2 和 3 可以形成一组候选，2 + 2 + 3 = 7 。注意 2 可以使用多次。7 也是一个候选， 7 = 7 。仅有这两种组合。 示例 2：输入: candidates = [2,3,5], target = 8输出: [[2,2,2,2],[2,3,3],[3,5]] 示例 3：输入: candidates = [2], target = 1输出: [] 12345678910111213141516171819class Solution { public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) { List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); backtrack(candidates, target, 0, new ArrayList&lt;Integer&gt;(), ans); return ans; } public void backtrack(int[] candidates, int remain, int index, List&lt;Integer&gt; path, List&lt;List&lt;Integer&gt;&gt; ans) { if(remain &lt; 0) return; if (remain == 0) { ans.add(new ArrayList(path)); } for (int i = index; i &lt; candidates.length; i++) { path.add(candidates[i]); backtrack(candidates, remain - candidates[i], i, path, ans); path.remove(path.size() - 1); } }} Combination Sum II 组合总和 II给定一个候选人编号的集合 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的每个数字在每个组合中只能使用 **一次 **。注意：解集不能包含重复的组合。 示例 1:输入: candidates = [10,1,2,7,6,1,5], target = 8,输出:[[1,1,6],[1,2,5],[1,7],[2,6]] 示例 2:输入: candidates = [2,5,2,1,2], target = 5,输出:[[1,2,2],[5]] 12345678910111213141516171819202122232425262728class Solution { public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) { List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;(); Arrays.sort(candidates); backtrack(candidates, target, 0, new ArrayList&lt;&gt;(), ans); return ans; } public void backtrack(int[] nums, int remain, int index, List&lt;Integer&gt; path, List&lt;List&lt;Integer&gt;&gt; ans) { if(remain &lt; 0){ return; } if (remain == 0) { ans.add(new ArrayList&lt;&gt;(path)); } for (int i = index; i &lt; nums.length; i++) { if (i &gt; index &amp;&amp; nums[i] == nums[i - 1]) { continue; } if (nums[i] &gt; remain) { // 其实和上面 remain &lt; 0 保留其一即可 break; } path.add(nums[i]); backtrack(nums, remain - nums[i], i + 1, path, ans); path.remove(path.size() - 1); } }}","link":"/2025/05/12/%E5%9B%9E%E6%BA%AF%E7%9B%B8%E5%85%B3%E9%A2%98%E7%9B%AE%E6%95%B4%E7%90%86/"},{"title":"多线程顺序打印问题","text":"三个线程分别打印 A，B，C三个线程分别打印 A，B，C，要求这三个线程一起运行，打印 n 次，输出形如“ABCABCABC….”的字符串 使用Lock12345678910111213141516171819202122232425262728293031323334353637383940import java.util.concurrent.locks.ReentrantLock;public class ABC { static class ABCPrinter { private final int times; // 需要打印的次数 private volatile int state; // 存储状态值，打印完成时该值会变成3*time-1 private final ReentrantLock lock; public ABCPrinter(int times) { this.times = times; this.lock = new ReentrantLock(); } public void print(Character key, int num) { int current = 0; while (current &lt; times) { lock.lock(); if (state % 3 == num) { // 通过取模判断当前该哪个线程进入打印 System.out.println(key); state++; current++; } lock.unlock(); // 打印完成或非当前线程轮次会进入解锁 } } } public static void main(String[] args) throws InterruptedException { final ABCPrinter abcPrinter = new ABCPrinter(10); Thread a = new Thread(() -&gt; abcPrinter.print('A', 0)); a.start(); Thread b = new Thread(() -&gt; abcPrinter.print('B', 1)); b.start(); Thread c = new Thread(() -&gt; abcPrinter.print('C', 2)); c.start(); a.join(); b.join(); c.join(); }} 使用wait/notify12345678910111213141516171819202122232425262728293031323334353637383940414243public class ABC { static class ABCPrinter { private final static Object LOCK = new Object(); private final int times; // 需要打印的次数 private volatile int state; // 存储状态值，打印完成时该值会变成3*time-1 public ABCPrinter(int times) { this.times = times; } public void print(Character key, int num) { int current = 0; while (current &lt; times) { synchronized(LOCK){ while (state % 3 != num) { // 存在虚假唤醒的问题，必须设置为while循环 try { LOCK.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } state++; current++; System.out.println(key); LOCK.notifyAll(); // notifyAll和wait方法必须放在synchronized中，不让编译器会抛出IllegalMonitorStateException } } } } public static void main(String[] args) throws InterruptedException { final ABCPrinter abcPrinter = new ABCPrinter(10); Thread a = new Thread(() -&gt; abcPrinter.print('A', 0)); a.start(); Thread b = new Thread(() -&gt; abcPrinter.print('B', 1)); b.start(); Thread c = new Thread(() -&gt; abcPrinter.print('C', 2)); c.start(); a.join(); b.join(); c.join(); }} 两个线程交替打印0~100的奇偶数两个线程交替打印0~100的奇偶数 使用wait/notify12345678910111213141516171819202122232425262728293031323334353637public class OddEvenPrinter { static class Printer { private final static Object LOCK = new Object(); private volatile int state = 0; private final int times; public Printer(int times) { this.times = times; } public void print(int mod) { while (state &lt; times) { synchronized (LOCK) { while (state % 2 != mod) { // 处理虚假唤醒 try { LOCK.wait(); } catch (InterruptedException e) { throw new RuntimeException(e); } } System.out.println(&quot;name: &quot; + Thread.currentThread().getName() + &quot;, number: &quot; + state++); LOCK.notify(); } } } } public static void main(String[] args) { Printer printer = new Printer(100); new Thread(() -&gt; printer.print(0)).start(); new Thread(() -&gt; printer.print(1)).start(); }} 通过N个线程顺序循环打印从0至100通过N个线程顺序循环打印从0至100 使用Semaphore12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.util.concurrent.Semaphore;public class NThreadPrinter { private final int limit = 100; // 打印的最大值 private final int threadCount; // 线程数 private volatile int state = 0; // 共享状态变量 private final Semaphore[] semaphores; // 每个线程对应的信号量 public NThreadPrinter(int threadCount) { this.threadCount = threadCount; semaphores = new Semaphore[threadCount]; // 初始化信号量，除了第一个线程信号量为 1，其它为 0 for (int i = 0; i &lt; threadCount; i++) { semaphores[i] = new Semaphore(i == 0 ? 1 : 0); } } public void print(int threadId) { while (true) { try { semaphores[threadId].acquire(); // 获取当前线程的信号量 if (state &gt; limit) { semaphores[(threadId + 1) % threadCount].release(); return; } // 打印完成，退出 System.out.println(&quot;线程 &quot; + threadId + &quot; 打印：&quot; + state++); // 唤醒下一个线程 semaphores[(threadId + 1) % threadCount].release(); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { int N = 3; // 线程数量 NThreadPrinter printer = new NThreadPrinter(N); // 启动 N 个线程 for (int i = 0; i &lt; N; i++) { final int threadId = i; new Thread(() -&gt; printer.print(threadId)).start(); } }}","link":"/2025/03/08/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%A1%BA%E5%BA%8F%E6%89%93%E5%8D%B0%E9%97%AE%E9%A2%98/"},{"title":"操作系统","text":"操作系统相关书籍：《Linux是怎样工作的 - [日]武内觉》 存储层次高速缓存从内存直接和寄存器之间做数据拷贝很慢，高速缓存的存在，正是为了抹平寄存器与内存之间的性能差距。 读取数据从内存读取数据时，数据显呗送往高速缓存，在被送往寄存器，读取的数据大小取决于缓存块大小（cache line size），该值由各个CPU规定。假设缓存块的大小为 10 字节，高速缓存的容量为 50 字节，并且存在两个长度为 10 字节的寄存器（R0 与 R1）。在这样的运行环境下，把内存地址 300 上的数据读取到 R0 时的情形如图 6-2 所示。此后，当 CPU 需要再次读取地址 300 上的数据时，比如需要再次把同样的数据读取到 R1 时，将不用从内存读取数据，只需读取已经存在于高速缓存上的数据即可 写入数据当需要将寄存器上的数据重新写回到地址 300 上时，首先会把改写后的数据写入高速缓存，如图 6-5 所示。此时依然以缓存块大小为单位写入数据。然后，为这些缓存块添加一个标记，以表明这部分从内存读取的数据被改写了。通常我们会称这些被标记的缓存块“脏了”。这些被标记的数据会在写入高速缓存后的某个指定时间点，通过后台处理写入内存。随之，这些缓存块就不再脏了 [3]，如图 6-6 所示。也就是说，只需要访问速度更快的高速缓存，即可完成图 6-5 中的写入操作","link":"/2025/04/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"计算机知识拓扑","text":"计算机知识拓扑操作系统、计算机网络、数据结构、编程语言等","link":"/2025/03/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9F%A5%E8%AF%86%E6%8B%93%E6%89%91/"},{"title":"高可用和稳定性","text":"多副本 本地缓存多副本 Redis多副本 MySQL多副本 消息中间件多副本 隔离、限流、熔断和降级隔离定义：将系统或资源分割开，在系统发生故障时能限定传播范围和影响范围，即发生故障后不会出现滚雪球效应 数据隔离 机器隔离 线程池隔离：为了某个rpc接口较慢导致线程池打满，为不同的rpc接口提供不同的线程池 信号量隔离：为了解决线程数过多导致上下文切换开销的大问题，共用线程池但是取线程之前需要获得信号量，信号量达到阈值则无法获取线程 限流定义：系统的处理能力不能应对外部请求的涂增流量时，为了不让系统崩溃（如线程池资源耗尽），需要采取限流的措施 方式 技术层面的限流限制并发数：比如数据库连接池、线程池、Nginx的limit_conn模块限制速率：比如Guava的RateLimiter、Nginx的limit_req模块 业务层面的限流如在秒杀系统中，一个商品的库存只有100件，现在有2万人抢购，没有必要放2万个人进来，只需要放前500个人进来，后面的人直接返回已售完即可。具体实现上，有团队使用Redis，也有团队直接基于Nginx+Lua脚本来实现 限流算法并发数限制限制并发数的计算原理很简单，系统只需要维护正在使用的资源数或空闲数，比如数据库的连接数、线程池的线程数 速率限制 固定窗口计数 方式： 在固定时间区间内统计请求数量 达到阈值后拒绝请求 缺点： 临界点爆发问题，0.99秒1000个请求，1.01秒1000个请求 突刺，0.1处理1000个请求，剩下0.9秒无法处理请求 滑动窗口计数 方式： 将时间窗口进一步细分为小块（比如1秒-&gt;10个0.1秒） 每个小窗口分别计数，滑动加总 优点：缓解临界爆发，流量统计更平滑 缺点：缓解临界爆发，不解决 滑动时间窗口 方式： 精确记录每次请求的时间戳 每次检查当前时间，除去超过时间范围的请求计数，计算窗口内真实数量 缺点：内存占用高，不适合高并发场景 漏桶算法 方式： 请求以仁义速度进入系统，被积压放入桶中，即入水速度任意 请求按固定速率处理（出水速率恒定），即出水速度恒定 请求可以缓冲排队，溢出直接丢弃 特点：平滑流量，不能积压太多突发流量 令牌桶算法 方式： 定时向桶内放入令牌（以固定速率） 每个请求拿一个令牌，拿到才能处理，没有就拒绝或者排队 特点：可以应对突发流量 漏桶算法 vs 令牌桶算法 - 漏桶算法 令牌桶算法 特点 流出速率保持恒定 流入速率保持恒定 用途 类似消息队列，起到了削峰的作用，平滑了突发流入速率 限制的是平均流入速率，可能一段时间没有请求令牌累积，突发流量一瞬间取令牌处理 熔断定义：当某个服务持续失败或响应异常，系统主动“断开”对它的调用一段时间，避免整个系统雪崩 根据请求失败率做熔断对于客户端调用的某个服务，如果服务在短时间内大量超时或抛错，则客户端直接开启熔断，也就是不再调用此服务。然后过一段时间，再把熔断打开，如果还不行，则继续开启熔断。这也正是经常提到的“快速失败（Fail Fast）”原则” 根据请求响应时间做熔断Sentinel 的思路根据请求响应时间做熔断。当资源的平均响应时间超过阈值后，资源进入准降级状态。接下来如果持续进入5个请求，且它们的RT 持续超过该阈值，那么在接下来的时间窗口内，对这个方法的调用都会自动地返回 降级定义：降级是一种兜底方案，是在系统出故障之后的一个尽力而为的措施。比如电商推荐系统，当宕机时，可以为首页准备一个非个性化的商品列表，甚至一个静态的商品列表","link":"/2025/05/03/%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E7%A8%B3%E5%AE%9A%E6%80%A7/"},{"title":"项目回顾","text":"大数据离线任务调度系统定义大数据离线任务调度系统 是指用于 管理、编排和执行批处理（离线）数据任务 的平台，它确保 数据在正确的时间、以正确的依赖关系顺序、在正确的计算资源上被处理，以支持数据仓库建设、ETL流程、数据分析、数据报表等工作。上下游关联：上层是数据开发平台、BI平台、机器学习平台等等，下层是Spark、MR、异步数据源同步引擎等底层引擎运行频率：一般是分钟级、小时级、日级 痛点问题 调度时延高：对于到达就绪时间的任务，旧架构下采取轮询的模式从DB查询任务，时延较高 有状态服务：服务内存中存储DAG结构，服务重启或故障情况下需要恢复内存状态 单点问题：服务发布、单点故障会导致服务不可用。 关键设计事件驱动+分布式非阻塞设计，有效降低任务和链路的调度时延 优点： 异步非阻塞：使得系统响应速度更快，延迟更低 扩展性强：事件可以作为切面，可以支持更丰富的hook逻辑，而不阻塞主业务逻辑 高可用：事件缓存在消息队列，部分服务器上的服务异常，不会影响服务整体的可用性 挑战： 事件幂等：事件消息生产-消费的过程中，为了避免网络问题等导致流程异常中断，一定会做重试。所以要对事件的处理做幂等处理。通过【状态机+事件去重】来做幂等 事件乱序并发：状态机校验+partition分区，同一任务相关事件单线程处理，类似actor模式，避免复杂的并发处理，避免在任务粒度上加分布式锁带来的性能开销 “无状态”服务基于缓存中间件存储DAG结构，服务重启或单点故障时无需做状态恢复 组件选型定时触发任务Quartz vs 延迟队列（kafka+tair时间轮） 消息队列Kafka vs rabbitMQ vs RocketMQ 分布式内存Redis-cluster vs Tair 分布式协调服务ZooKeeper vs ETCD 详细设计延迟队列：对比Quartz等分布式方案，没有使用分布式锁，而是基于kafka+tair用时间轮实现，延迟更低事件消费速度：partition单线程拉取+多线程批量消费，滑动窗口ACK分布式有序提交：mr模式，map基于sorted set设计的优先级队列，reduce采用dispacther线程单线程提交，多实例采用zk公平锁实现均衡自动容错：服务重启，节点宕机情况下能自动容错。注册中心zk不停机运维：版本号的事件设计，运维操作需要与调度并行，对于子DAG的运维需要在不影响其他任务的前提下，不受非运维消息的影响 问题与解决方案Q：单线程dispatcher缓存操作效率低A：批处理+pipeline Q：未知原因导致调度慢？CPU指标较高？A：redis监控，服务日志无异常。Arthas火焰图大部分时间做监控数据上报，调小监控上报的线程池大小 Q：kafka partition批量消费加了内存锁，一个事件处理线程卡住？A：jstack发现一个线程卡住，定位到实现的一个LockManager对于unlock操作不当 Q：上游触发下游执行时给事件赋值版本号，此时可能同时存在运维动作A：版本号+上游依赖版本 大数据资产管理与治理平台提升数据资产(Hive 表、Spark、Flink 任务等)全方位可视化管理、优化资源利用、实现智能治理，并提供量化收益评估，最终推动资源合理使用，提高数据资产的整体价值 痛点问题业务痛点：分区生命周期应该配置多久？如果发现无效的离线数仓表/任务？怎么常态化推动持续治理？技术难点：复杂业务流程建模、流程自动化、流程可视化。等待用户确认，操作分区数据等能力做抽象，具备复用能力 关键设计fe：主要负责资产360，资产问题发现与治理spark+hive/es构建资产元数据，SpringBoot+es+doris搭建资产管理与治理系统。定义问题资产评估标准，定期扫描百万级数据表/任务，辅助定位资源问题，同时提供治理流程追踪与自动化治理，提升治理效率be：主要承载资产管理能力，如表及分区周期清理、降低副本、ORC压缩spiffworkflow：python实现的一套BPMN workflow框架，组织各种同步/异步任务的处理流程celery：异步任务处理","link":"/2025/04/18/%E9%A1%B9%E7%9B%AE%E5%9B%9E%E9%A1%BE/"},{"title":"高并发问题","text":"问题分类侧重于“高并发读”的系统例如如下场景 搜索引擎 电商的商品搜索 电商系统的商品描述、图片和价格 侧重于“高并发读”的系统例如如下场景 广告扣费系统 同时侧重于“高并发读”和“高并发写”的系统例如如下场景 电商的库存系统和秒杀系统 支付系统和微信红包 IM、微博和朋友圈 高并发读策略：加缓存本地缓存或Memcached/Redis集中式缓存当数据库支持不住的时候，首先想到的就是为其加一层缓存。缓存通常有两种思路：一种是本地缓存，另一种是Memcached/Redis类的集中式缓存使用缓存时需要考虑一些问题， 缓存雪崩： 定义：大量缓存同时无法访问，会导致所有请求全部访问并压垮数据库 发生原因： 大量缓存数据同时过期 Redis故障 处理方案 大量缓存数据同时过期：1. key的过期时间随机设置 2.请求数据库排队处理。 Redis故障：1.redis高可用机制 2. 服务熔断或请求限流机制 缓存穿透 定义：大量访问不存在的key，会导致请求全部访问并压垮数据库 发生原因：访问的数据既不在数据库，也不在缓存中 处理方案 非法请求的限制 缓存空值或者默认值 布隆过滤器 缓存击穿： 定义：热点数据过期，对热点数据的访问会全部访问并压垮数据库 发生原因：热点数据过期 处理方案： 热点数据永不过期，或者续期 排队降级访问数据库，第一个降级的查询会重新更新缓存 MySQL的Master/Slave主库负责读写，从库负责读 CDN静态文件加速（动静分离）将图片、HTML、JS、CSS 文件等静态文件缓存到全网的各个节点，用户访问时就进读取 策略 ：并发读 异步调用（RPC）：没有耦合关系的多个接口可以并行调用 冗余请求：单台机器的调用延迟概率时1%，100台机器的延迟概率就是1-(99%)^100=63%，延迟的概率很高。客户端同时向多台服务器发送请求，哪个返回得快就用哪个，其他的丢弃，但这会让整个系统的调用量翻倍","link":"/2025/05/04/%E9%AB%98%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98/"},{"title":"interview record 0","text":"Java 10亿数取TOPKHive SQL 最近7天连续登陆3天的用户 每科排名前3的学生 自我介绍项目经历kafka isr集合作用kafka副本同步机制kafka如何保证数据不丢失项目和airflow、dolphinscheduler相比优势是什么？事件驱动，延迟队列（没说出来）项目设计比较好的地方？延迟队列（没说出来），批处理优化（没说出来），dag运行干预（没说出重点）依赖上游任务情况下，希望最晚等到几点就开始执行，怎么设计？弱依赖最晚等待时间java基本数据类型？说的比较混乱jvm内存模型类加载器java垃圾回收算法jdk11默认的垃圾回收器hdfs文件读取流程小文件处理流程spark提交任务流程spark为什么比mr快 老鼠试毒药最少多少只老鼠可以试出来","link":"/2025/05/19/interview-record-0/"},{"title":"常用的设计模式","text":"单例模式工厂模式建造者模式策略模式代理模式","link":"/2025/05/20/%E5%B8%B8%E7%94%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Akka","slug":"Akka","link":"/tags/Akka/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"调度","slug":"调度","link":"/tags/%E8%B0%83%E5%BA%A6/"},{"name":"Interview","slug":"Interview","link":"/tags/Interview/"},{"name":"中间件","slug":"中间件","link":"/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"大数据","slug":"大数据","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"架构设计","slug":"架构设计","link":"/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"项目回顾","slug":"项目回顾","link":"/tags/%E9%A1%B9%E7%9B%AE%E5%9B%9E%E9%A1%BE/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"调度服务","slug":"调度服务","link":"/categories/%E8%B0%83%E5%BA%A6%E6%9C%8D%E5%8A%A1/"},{"name":"Interview","slug":"Interview","link":"/categories/Interview/"},{"name":"Database","slug":"Database","link":"/categories/Database/"},{"name":"大数据","slug":"Interview/大数据","link":"/categories/Interview/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"编程语言","slug":"Interview/编程语言","link":"/categories/Interview/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"🍺 Code Interview","slug":"Interview/🍺-Code-Interview","link":"/categories/Interview/%F0%9F%8D%BA-Code-Interview/"},{"name":"中间件","slug":"Interview/中间件","link":"/categories/Interview/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"架构设计","slug":"Interview/架构设计","link":"/categories/Interview/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"name":"操作系统","slug":"Interview/操作系统","link":"/categories/Interview/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"0.知识拓扑","slug":"Interview/0-知识拓扑","link":"/categories/Interview/0-%E7%9F%A5%E8%AF%86%E6%8B%93%E6%89%91/"},{"name":"项目回顾","slug":"Interview/项目回顾","link":"/categories/Interview/%E9%A1%B9%E7%9B%AE%E5%9B%9E%E9%A1%BE/"},{"name":"设计模式","slug":"Interview/设计模式","link":"/categories/Interview/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}