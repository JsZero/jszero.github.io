{"pages":[{"title":"关于","text":"一个菜鸟码农的空间🏔 沿途的风景 🐕 家里的小柴犬“卷饼” 🎶 听过的演唱会 🍲 品尝过的美食","link":"/about/index.html"}],"posts":[{"title":"Akka使用教程","text":"Akka 是一个用 Scala 编写的库，用于在 JVM 平台上简化编写具有可容错的、高可伸缩性的 Java 和 Scala 的 Actor 模型应用，其同时提供了Java 和 Scala 的开发接口。Akka 允许我们专注于满足业务需求，而不是编写初级代码。在 Akka 中，Actor 之间通信的唯一机制就是消息传递。Akka 对 Actor 模型的使用提供了一个抽象级别，使得编写正确的并发、并行和分布式系统更加容易。Actor 模型贯穿了整个 Akka 库，为我们提供了一致的理解和使用它们的方法 ActorsIntroduction to Actors待补充","link":"/2022/07/02/Akka%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"},{"title":"DolphinScheduler源码阅读日记（三）通信机制","text":"概述DolphinScheduler的通信机制是通过Netty来实现的，在Netty上加做了一些封装和抽象 Netty简介功能介绍Netty 是一个基于 Java 的高性能网络应用框架，广泛用于开发高并发、低延迟的网络服务器和客户端。它提供了一组丰富的 API 和工具，简化了网络通信的开发过程，特别是在处理大量并发连接和数据流时。 为各种传输类型（阻塞和非阻塞socket）提供统一API 基于灵活且可扩展的事件模型，允许明确分离关注点 高度可定制的线程模型——单线程、一个或多个线程池（如 SEDA） 真正的无连接数据报socket支持（自3.1版起） 基础概念 table th:first-of-type {width: 20%;} table th:nth-of-type(2) {width: 80%;} 概念 含义 Channel Channel 是 Netty 中用于网络通信的基本抽象，表示一个到网络套接字（Socket）的连接。它类似于 Java NIO 的 Channel，但提供了更多的高级功能。Channel 可以是 TCP、UDP 或者文件传输等不同类型的连接 EventLoop EventLoop 是 Netty 中的事件处理核心。每个 EventLoop 都与一个或多个 Channel 关联，负责处理这些 Channel 上的所有 I/O 操作，包括读写事件的调度。EventLoop 使用单线程模式，可以有效地避免线程间竞争 ChannelHandler ChannelHandler 是用于处理 Channel 上的 I/O 事件的组件。Netty 通过 ChannelHandler 实现了灵活的事件处理机制。常见的 ChannelHandler 类型包括 ChannelInboundHandler 和 ChannelOutboundHandler，分别用于处理入站和出站数据 Pipeline Pipeline 是 Netty 中的一个重要概念，它是 ChannelHandler 的有序链表。所有与 Channel 相关的事件（如读、写、连接等）都会沿着 Pipeline 依次传递。开发者可以根据需要在 Pipeline 中插入不同的 ChannelHandler 来实现定制的逻辑 Bootstrap Bootstrap 是用于配置和启动客户端或服务器端 Channel 的类。它简化了网络应用程序的启动过程，开发者可以通过 Bootstrap 设置相关参数，如线程池、事件处理器等 ByteBuf ByteBuf 是 Netty 提供的用于高效处理字节数据的缓冲区。与 Java NIO 中的 ByteBuffer 不同，ByteBuf 提供了更多的操作方法，并且支持动态扩展、引用计数等特性，极大地提高了处理二进制数据的效率 Future&amp;Promise Future 和 Promise 是 Netty 中的异步编程模型，用于表示异步操作的结果。Future 表示一个尚未完成的操作结果，而 Promise 则是可以手动设置结果的 Future。这两个接口帮助开发者处理异步任务的回调逻辑 Transport Transport 是 Netty 中的底层抽象，负责实现具体的网络协议（如 TCP、UDP）的传输机制。不同的 Transport 实现可以有不同的 I/O 模型（如 NIO、Epoll 等），适用于不同的操作系统和性能需求 通信机制实现关键类在MasterServer、WorkerServer中分别都存在一个RpcServer和RpcClient，用于作为RPC的服务端和客户端 序列化与反序列化Messgae的序列化与反序列化 事件处理器如何映射到对应的Processor处理（值得借鉴）##","link":"/2024/08/23/DolphinScheduler%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E6%97%A5%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/"},{"title":"Flink源码编译","text":"前言学习一下Flink的执行原理，需要在本地编译源码好debug运行。 编译环境 环境 版本 系统 m1 pro macbook pro 14 JRE Zulu 8.62.0.19-CA-macos-aarch64 Flink release-1.12.7-rc1 编译过程1mvn clean package -DskipTests -Dhadoop.version=2.7.1 参考下Building Apache Flink from Source 编译过程中产生如下异常并解决 报错：安装node和npm失败1[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.6:install-node-and-npm (install node and npm) on project flink-runtime-web_2.11: Could not download Node.js: Could not download https://nodejs.org/dist/v10.9.0/node-v10.9.0-darwin-arm64.tar.gz: nodejs.org:443 failed to respond -&gt; [Help 1] 解决方案：参考eirslett/frontend-maven-plugin issue 952，FLINK-23230提到的问题修改flink/flink-runtime-web/pom.xml文件中frontend-maven-plugin的版本为1.11.0，发现还是有443异常，后来发现是maven的settings.xml中配置的proxy走的是sock5，修改成http代理后恢复正常","link":"/2022/07/03/Flink%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"},{"title":"leetcode 31. 下一个排列","text":"https://leetcode.com/problems/next-permutation/description/ 31.下一个排列 整数数组的排列是将其成员排列成序列或线性顺序。 例如，对于arr = [1,2,3]，arr的所有排列如下：[1,2,3]，[1,3,2]，[2,1,3]，[2,3,1]，[3,1,2]，[3,2,1]。整数数组的下一个排列是它的整数下一个字典序排列。更正式地说，如果将数组的所有排列按字典序排序放入一个容器中，那么该数组的下一个排列就是排序容器中紧随其后的排列。如果无法进行这种排列，则数组必须重新排列为最低可能的顺序（即按升序排序）。 例如，arr = [1,2,3]的下一个排列是[1,3,2]。 同样，arr = [2,3,1]的下一个排列是[3,1,2]。 而arr = [3,2,1]的下一个排列是[1,2,3]，因为[3,2,1]没有字典序更大的排列。给定一个整数数组nums，找到nums的下一个排列。替换必须就地完成，并且只能使用常量额外内存。 示例 1：输入：nums = [1,2,3]输出：[1,3,2] 示例 2：输入：nums = [3,2,1]输出：[1,2,3] 示例 3：输入：nums = [1,1,5]输出：[1,5,1] 约束条件： 1 &lt;= nums.length &lt;= 100 0 &lt;= nums[i] &lt;= 100 解法关键点：考虑一种比较复杂的情况，如[2,3,5,4,1]，它的下一个排列是[2,4,1,3,5]。这种下一个排列是怎么出现的呢， 对于位置i来讲，在(i, n-1]的区间上如果存在位置j，使得最小的nums[j]满足nums[j]&gt;nums[i]，我们应该把它冒泡出来，换到i的位置上，在这个例子中就是把4换到3的位置上，集合变成[2,4,5,3,1]。即从右侧开始找到第一个升序对，交换位置。这样，一个较大的数就“晋升”上来了 寻找右侧开始的升序对时，不需要做O(n^2)的遍历，因为除了这个升序对之外其他都是降序的，所以我们可以做到O(2n)的时间复杂度，第一步只要找到比nums[i+1]小的数字nums[i]，nums[i]就是升序对的左侧值，再重新从数组nums右侧开始遍历，找到第一个比nums[i]大的nums[j]就可以了，j不一定等于i+1 接着我们只要把剩余的部分[i+1, n-1]做升序排序就可以了，这里面有一个优化可以避免直接O(log n)排序。当我们找到了位置j之后，有nums[i]&lt;nums[j]，对于j来讲有nums[i+1]&gt;...&gt;nums[j]...&gt;nums[n-1]，所以经过第1步的交换后的序列在[i+1, n-1]的区间上仍然是降序的，而我们只要用双指针从左右向中间夹，左右指针数值交换，就能把降序转升序了 对于[i+1, j-1]区间的x来讲，一定nums[i]&gt;nums[x]，不然第一步找出来的位置就不是j了， 对于[j+1, n-1]区间的y来讲，一定nums[i]&gt;nums[y]，不然第一步找出来的位置就不是j了， 1234567891011121314151617181920212223242526class Solution { public void nextPermutation(int[] nums) { int idx = -1; for (int i = nums.length - 2; i &gt;= 0; i--) { if (nums[i] &lt; nums[i + 1]) { idx = i; break; } } if (idx != -1) { for (int i = nums.length - 1; i &gt; idx; i--) { if (nums[i] &gt; nums[idx]) { int tmp = nums[idx]; nums[idx] = nums[i]; nums[i] = tmp; break; } } } for (int start = idx + 1, end = nums.length - 1; start &lt; end; start++, end--) { int tmp = nums[start]; nums[start] = nums[end]; nums[end] = tmp; } }}","link":"/2025/04/20/leetcode-31-%E4%B8%8B%E4%B8%80%E4%B8%AA%E6%8E%92%E5%88%97/"},{"title":"DolphinScheduler源码阅读日记（一）开发环境搭建","text":"系统环境 环境 版本 系统 macOS 12.2.1/m1 pro JRE Zulu 8.62.0.19-CA-macos-aarch64 Maven 3.8.6 Node 18.4.0 Pnpm 7.3.0 Zookeeper 3.8.4 MySQL 8.0.28 DolphinScheduler 3.2.0 搭建项目开发环境项目下载从github下载源码从dolphinscheduler源码仓库下载源码 12git clone https://github.com/apache/dolphinschedulergit checkout 3.2.0 # 切换到3.2.0分支 Zookeeper下载二进制可执行包 下载Zookeeper 3.8.4二进制可执行包 创建文件&amp;日志目录 解压压缩包，创建data、datalog目录 123cd /Users/jiashaoqi/plugin/zookeepertar -zxvf apache-zookeeper-3.8.4-bin.tar.gzmkdir data datalog 修改配置文件将conf目录下的zoo_sample.cfg文件，复制一份，重命名为zoo.cfg，修改其中数据和日志的配置，如： 123cd ./apache-zookeeper-3.8.4-bin/confcp zoo_sample.cfg zoo.cfgvi zoo.cfg 添加环境变量12vi ~/.bash_profile # 添加内容如下source ~/.bash_profile 启动Zookeeper1zkServer.sh start # 见到如图所示即为启动成功 MySQL数据库配置初始化数据库及账号创建完新数据库dolphinscheduler后，将dolphinscheduler/dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql下的sql文件直接在MySQL中运行，完成数据库初始化 1234567891011121314151617181920mysql&gt; create database dolphinscheduler;Query OK, 1 row affected (0.01 sec)mysql&gt; create user 'dolphin'@'localhost' identified by 'nihplod';Query OK, 0 rows affected (0.01 sec)mysql&gt; grant all privileges on dolphinscheduler.* to 'dolphin'@'localhost';Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; use dolphinscheduler;Database changedmysql&gt; source /Users/jiashaoqi/workspace/idea/dolphinscheduler/dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql;Query OK, 1 row affected (0.00 sec)...Query OK, 1 row affected (0.00 sec) 后端Maven依赖下载通过idea打开项目，下载依赖，这可能需要一段时间 注意：maven下载依赖可能会出现问题，对于下载出错的依赖或者插件，可以到本地maven仓库目录下删除对应的子目录重新下载，如在下载依赖后编译时发生了如下异常 1java: 读取/Users/jiashaoqi/plugin/maven/apache-maven-3.8.6/repo/io/fabric8/kubernetes-model-core/5.10.2/kubernetes-model-core-5.10.2.jar时出错; zip file is empty 所以手动下载依赖kubernetes-model-core 12rm -rfv /Users/jiashaoqi/plugin/maven/apache-maven-3.8.6/repo/io/fabric8/kubernetes-model-core/5.10.2mvn dependency:get -DgroupId=io.fabric8 -DartifactId=kubernetes-model-core -Dversion=5.10.2 修改数据库配置 将dolphinscheduler-bom/pom.xml文件中mysql-connector-java依赖的scope修改为compile 将如下配置文件中的mysql的datasource配置为如下内容12345dolphinscheduler-master/src/main/resources/application.yaml:151dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/resources/application.yaml:93dolphinscheduler-api/src/main/resources/application.yaml:229dolphinscheduler-standalone-server/src/main/resources/application.yaml:305dolphinscheduler-tools/src/main/resources/application.yaml:49 配置名 配置值 datasource.driver-class-name com.mysql.cj.jdbc.Driver datasource.url jdbc:mysql://127.0.0.1:3306/dolphinscheduler datasource.username dolphin datasource.password nihplod 修改日志级别为以下配置增加一行内容 使日志能在命令行中显示 123dolphinscheduler-master/src/main/resources/logback-spring.xmldolphinscheduler-worker/src/main/resources/logback-spring.xmldolphinscheduler-api/src/main/resources/logback-spring.xml 12345&lt;root level=&quot;INFO&quot;&gt;+ &lt;appender-ref ref=&quot;STDOUT&quot;/&gt; &lt;appender-ref ref=&quot;APILOGFILE&quot;/&gt; &lt;appender-ref ref=&quot;SKYWALKING-LOG&quot;/&gt;&lt;/root&gt; 可以再在STDOUT这个appender的pattern上套一个%clr(...)，让日志在控制台上高亮显示，如 12345678910111213&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;120 seconds&quot;&gt;+ &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot; /&gt; &lt;!-- ... --&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;+ %clr([%level] %date{yyyy-MM-dd HH:mm:ss.SSS Z} %logger{96}:[%line] - [WorkflowInstance-%X{workflowInstanceId:-0}][TaskInstance-%X{taskInstanceId:-0}] - %msg%n) &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- ... --&gt;&lt;/configuration&gt; 编译源代码 运行后端服务参考DolphinScheduler 普通开发模式需要启动三个服务，包括 MasterServer，WorkerServer，ApiApplicationServer MasterServer：在 Intellij IDEA 中执行 org.apache.dolphinscheduler.server.master.MasterServer 中的 main 方法，并配置 VM Options -Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql WorkerServer：在 Intellij IDEA 中执行 org.apache.dolphinscheduler.server.worker.WorkerServer 中的 main 方法，并配置 VM Options -Dlogging.config=classpath:logback-spring.xml -Ddruid.mysql.usePingMethod=false -Dspring.profiles.active=mysql ApiApplicationServer：在 Intellij IDEA 中执行 org.apache.dolphinscheduler.api.ApiApplicationServer 中的 main 方法，并配置 VM Options -Dlogging.config=classpath:logback-spring.xml -Dspring.profiles.active=api,mysql。启动完成可以浏览 Open API 文档，地址为 http://localhost:12345/dolphinscheduler/swagger-ui/index.html 前端安装依赖，运行前端服务123cd dolphinscheduler-uipnpm installpnpm run dev 截止目前，前后端已成功运行起来，浏览器访问 http://localhost:5173 ，并使用默认账户密码 admin/dolphinscheduler123 即可完成登录 完成环境搭建搭建成功效果","link":"/2024/07/27/Dolphinscheduler%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E6%97%A5%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"MySQL实战45讲-阅读笔记","text":"SQL查询语句的执行执行流程如下具体拆解如下， 连接器 长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。使用长连接可能会导致MySQL占用内存快速上涨，原因是执行过程中临时使用的内存是管理在连接对象里面的，这些资源会在连接断开的时候才释放。解决方案有两个 定期断开长连接 MySQL 5.7或更新版本可以执行mysql_reset_connection来重新初始化连接资源 查询缓存 除非是静态表，否则不建议开启查询缓存。表只要有一次更新操作，表关联所有缓存都失效。MySQL 8.0及以上缓存功能已被废弃 分析器：依次进行如下分析，不符合词法或语法则抛出异常 ①词法分析：解析关键字和字段名 ②语法分析：判断是否符合MySQL语法 优化器：决定SQL的执行顺序 执行器：表权限校验，调用查询引擎接口根据索引（如果有）查询数据 SQL更新语句的执行执行流程和查询语句的流程一样，如下 redo log和binlog除此以外，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志） redo log - InnoDB引擎特有的日志，可以保证crash-safe。 - 物理日志，记录的是“在某个数据页上做了什么修改”。 - 循环写的，空间固定会用完。如下所示，write pos是当前记录的位置，一边写一边后移，checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos和checkpoint之间的是还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示redolog满了不能再执行新的更新，得停下来先擦掉一些记录写入binlog，把checkpoint推进一下。 binlog - MySQL的Server层实现的，所有引擎都可以使用，用于归档。 - 逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1”。 - 可以追加写入的。binlog文件写到一定大小后会切换到下一个，不会覆盖以前的日志。 update语句的执行流程update语句的执行流程如下，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。redo log的写入拆成了两个步骤：prepare和commit，也就是”两阶段提交”。 🔥事务的隔离级别隔离性与隔离级别 table th:first-of-type {width: 25%;} table th:nth-of-type(2) {width: 75%;} 级别 含义 读未提交 一个事务还没提交时，它做的变更就能被别的事务看到 读提交 一个事务提交之后，它做的变更才会被其他事务看到 可重复读 一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的 串行化 对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行 级别 结果 读未提交 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2 读提交 则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2 可重复读 则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的 串行化 则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2 🔥事务隔离的实现事务隔离具体是怎么实现的，这里以“可重复读”为例展开说明一下。 在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view.如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。回滚日志不会一直保留，在不需要的时候才删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。所以不建议用长事务，长事务意味着系统里面会存在很老的事务视图，因此回滚日志会占用大量存储资源，还占用锁资源，也可能拖垮整个库。 深入浅出索引索引的数据结构哈希表：适用于只有等值查询的场景 有序数组：在等值查询和范围查询场景中的性能就都非常优秀。但是插入效率较低，只适用于静态存储引擎 搜索树：使用N叉搜索树 为什么不使用二叉搜索树：索引数据存储在磁盘上，二叉搜索树节点只存储一个数据，树比较高，一次查询需要更多次的数据块读取 InnoDB 的索引模型在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用了B+树索引模型，数据都是存储在B+树中。 每一个索引在InnoDB里面对应一棵B+树。以如下的建表语句为例，索引树结构如下图所示 12345create table T( id int primary key, k int not null, name varchar(16),index (k))engine=InnoDB; 主键索引：也叫聚簇索引，叶子节点存的是整行数据普通索引：也叫二级索引，非聚簇索引，叶子节点内容是主键的值 Q：基于主键索引和普通索引的查询有什么区别？A：主键查询方式，则只需要搜索主键这棵B+树。普通索引查询方式，则需要先搜索普通索引树，得到叶节点上的主键值，再到主键索引树搜索一次。这个过程称为回表 索引维护B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。 如果插入一个更大的值，只需要在最后面插入一个新记录。 如果在中间插入一个值，处理比较麻烦，需要逻辑上挪动后面的数据，空出位置。 而更糟的情况是，如果数据所在的数据页已经满了，根据B+树的算法，需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂，插入性能因此会受到影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。 Q：哪些场景下应该使用自增主键，而哪些场景下不应该?A： 自增主键的插入数据模式，正符合递增插入的场景。每次插入一条新记录都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。其次，在考虑主键字段的选择时，由于普通索引的叶节点存储的是主键，因此主键越小普通索引占用的空间就更小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。 覆盖索引在普通索引上，叶节点上存储了相关字段和主键的数据，如果查询的是这部分字段可以避免回表查询，提高查询效率，减少树的搜索次数，显著提升查询性能 最左前缀原则B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。 Q：在建立联合索引的时候，如何安排索引内的字段顺序？A： 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。如果既有联合查询，又有基于a、b各自的查询呢？这时候需要同时维护类似(a,b)、(b) 这两个索引。此时，我们要考虑的原则就是空间，比如上有两个字段name、age，name字段是比age字段大的 ，那我就建议你创建一个（name,age)的联合索引和一个(age)的单字段索引。 索引下推举例，比如表存在name、age的联合索引，在执行如下语句时， 1select * from tuser where name like '张%' and age=10 and ismale=1; 如果没有索引下推，会回表依次查询记录的age、ismale是否符合要求 如果存在索引下推（MySQL5.6引入），会先根据索引上的数据对age进行过滤，再回表查询记录的ismale是否符合要求，这样的回表次数会更少 🔥锁机制根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类。 全局锁顾名思义，全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的典型使用场景是，做全库逻辑备份。 如果库下的表都是InnoDB表，在使用逻辑备份工具mysqldump时可以使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。 表级锁MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL）。表锁的语法是 lock tables … read/write。与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。 另一类表级的锁是MDL（metadata lock）。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 Q：为什么修改表结构操作可能出现问题？A： 如果表正在被读，一些session因此获取了读锁，在进行修改表结构操作获取写锁的时候就会阻塞住，此时如果再发生其他申请读锁的session，这些session也会全部被阻塞住。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新session再请求的话，这个库的线程很快就会爆满。 Q：如何安全地给小表加字段？A： 首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。如果要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，该怎么做呢？为alter table操作增加超时 🔥行锁MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，这就会影响到业务并发度。InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。 🔥两阶段锁协议在下面的操作序列中，事务B的update语句执行时会是什么现象呢？假设字段id是表t的主键。结果取决于事务A在执行完两条update语句后，持有哪些锁，以及在什么时候释放。 实际上事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行。因此事务A持有的两个记录的行锁，都是在commit的时候才释放的。 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。这样操作可以最大程度地减少事务之间的锁等待，提升并发度。 死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。如下图所示，事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。 出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。 在InnoDB中，innodb_lock_wait_timeout的默认值是50s，对于在线服务来说一般是无法接受的。但是不能把这个值设得很小，因为正常的锁等待也有可能被错误地释放。所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，但是每个新的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的，会消耗大量的CPU资源。 怎么解决由这种热点行更新，导致的死锁检测耗费大量CPU资源的问题呢？ 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是大部分业务设计时不会把死锁当做一个严重错误，遇到异常业务重试就完了，如果锁等待超时的话对业务来说是有损的。 控制并发度，在数据库服务端对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。如果数据库层面没有团队支持，可以考虑通过将一行改成逻辑上的多行来减少锁冲突。 🔥事务隔离级别的原理在第3章中曾经提到过，如果是可重复读隔离级别，事务T启动的时候会创建一个视图read-view，之后事务T执行期间，即使有其他事务修改了数据，事务T看到的仍然跟在启动时看到的一样。 但是，在第4章中，关于行锁的描述时又提到，一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？ 以如下这个表为例， 123456mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `k` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2); 关于事务的启动时机，begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用start transaction with consistent snapshot 这个命令。在本笔记中，如果没有特别说明，都是默认autocommit=1。 令人惊讶地，结果是事务B查到的k的值是3，而事务A查到的k的值是1，具体原因会在后面介绍。 在MySQL里，有两个“视图”的概念： 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view … ，而它的查询方法与表一样。 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现 🔥MVCC是如何提供“快照”的InnoDB里面每个事务有一个唯一的事务ID，叫作transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。 而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。 也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id。 如下图所示，就是一个记录被多个事务连续更新后的状态。 图中虚线框里是同一行数据的4个版本，当前最新版本是V4，k的值是22，它是被transaction id 为25的事务更新的，因此它的row trx_id也是25。 图中的三个虚线箭头，就是undo log；而V1、V2、V3并不是物理上真实存在的，而是每次需要的时候根据当前版本和undo log计算出来的。 那么InnoDB是怎么定义快照的？按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见 在实现上， InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。 数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。 而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。 这个视图数组把所有的row trx_id 分成了几种不同的情况。 这样，对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能： 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况 a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见； b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。 有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，生成的版本一定属于上面的2或者3(a)的情况，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。 所以你现在知道了，InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。 继续看一下图1中的三个事务，分析下事务A的语句返回的结果，为什么是k=1。 这里，我们不妨做如下假设： 事务A开始前，系统里面只有一个活跃事务ID是99； 事务A、B、C的版本号分别是100、101、102，且当前系统里只有这四个事务； 三个事务开始前，(1,1)这一行数据的row trx_id是90。 这样，事务A的视图数组就是[99,100], 事务B的视图数组是[99,100,101], 事务C的视图数组是[99,100,101,102]。 为了简化分析，我先把其他干扰语句去掉，只画出跟事务A查询逻辑有关的操作： 从图中可以看到，第一个有效更新是事务C，把数据从(1,1)改成了(1,2)。这时候，这个数据的最新版本的row trx_id是102，而90这个版本已经成为了历史版本。 第二个有效更新是事务B，把数据从(1,2)改成了(1,3)。这时候，这个数据的最新版本（即row trx_id）是101，而102又成为了历史版本。 你可能注意到了，在事务A查询的时候，其实事务B还没有提交，但是它生成的(1,3)这个版本已经变成当前版本了。但这个版本对事务A必须是不可见的，否则就变成脏读了。 好，现在事务A要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务A查询语句的读数据流程是这样的： 找到(1,3)的时候，判断出row trx_id=101，比高水位大，处于红色区域，不可见； 接着，找到上一个历史版本，一看row trx_id=102，比高水位大，处于红色区域，不可见； 再往前找，终于找到了(1,1)，它的row trx_id=90，比低水位小，处于绿色区域，可见。 这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。这个判断规则是从代码逻辑直接转译过来的，但是正如你所见，用于人肉分析可见性很麻烦。 所以翻译一下。一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。 对于可重复读的隔离级别，记住这个规则就可以来分析了。 🔥更新逻辑事务B的update语句，如果按照一致性读，好像结果不对？如下图，事务B的视图数组是先生成的，之后事务C才提交，不是应该看不见(1,2)吗，怎么能算出(1,3)来的？ 是的，如果事务B在更新之前查询一次数据，这个查询返回的k的值确实是1。但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务C的更新就丢失了。因此，事务B此时的set k=k+1是在（1,2）的基础上进行的操作。 所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。 因此，在更新的时候，当前读拿到的数据是(1,2)，更新后生成了新版本的数据(1,3)，这个新版本的row trx_id是101。 其实，除了update语句外，select语句如果加锁，也是当前读。所以，如果把事务A的查询语句select * from t where id=1修改一下，加上lock in share mode 或 for update，也都可以读到版本号是101的数据，返回的k的值是3。下面这两个select语句，就是分别加了读锁（S锁，共享锁）和写锁（X锁，排他锁）。 12select k from t where id=1 lock in share mode;select k from t where id=1 for update; 再进一步，假设事务C不是马上提交的，而是变成了下面的事务C’（如下右图所示），会怎么样呢？ 事务C’的不同是，更新后并没有马上提交，在它提交前，事务B的更新语句先发起了。前面说过了，虽然事务C’还没提交，但是(1,2)这个版本也已经生成了，并且是当前的最新版本。那么，事务B的更新语句会怎么处理呢？ 这时候，我们在上一篇文章中提到的“两阶段锁协议”就要上场了。事务C’没提交，也就是说(1,2)这个版本上的写锁还没释放。而事务B是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务C’释放这个锁，才能继续它的当前读。如下图所示 综上所述，事务的可重复读的能力是怎么实现的？ 可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。","link":"/2025/02/15/MySQL%E5%AE%9E%E6%88%9845%E8%AE%B2-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"title":"DolphinScheduler源码阅读日记（二）MasterServer工作流调度源码解析","text":"系统架构 MasterServer MasterServer采用分布式无中心设计理念，MasterServer主要负责 DAG 任务切分、任务提交监控，并同时监听其它MasterServer和WorkerServer的健康状态。 MasterServer服务启动时向Zookeeper注册临时节点，通过监听Zookeeper临时节点变化来进行容错处理。 MasterServer基于netty提供监听服务。 该服务内主要包含: DistributedQuartz: 分布式调度组件，主要负责定时任务的启停操作，当quartz调起任务后，Master内部会有线程池具体负责处理任务的后续操作； MasterSchedulerService: 是一个扫描线程，定时扫描数据库中的t_ds_command表，根据不同的命令类型进行不同的业务操作； WorkflowExecuteRunnable: 主要是负责DAG任务切分、任务提交监控、各种不同事件类型的逻辑处理； TaskExecuteRunnable: 主要负责任务的处理和持久化，并生成任务事件提交到工作流的事件队列； EventExecuteService: 主要负责工作流实例的事件队列的轮询； StateWheelExecuteThread: 主要负责工作流和任务超时、任务重试、任务依赖的轮询，并生成对应的工作流或任务事件提交到工作流的事件队列； FailoverExecuteThread: 主要负责Master容错和Worker容错的相关逻辑； 核心概念 table th:first-of-type {width: 25%;} table th:nth-of-type(2) {width: 75%;} 概念 含义 Process Definition 工作流定义 Process Instance 工作流实例，实际运行时会被包装为WorkflowExecuteRunnable Command 事件消息 关键流程分析 以下流程都在MasterServer中执行，不再在标题中赘述 拉取事件MasterSchedulerBootstrap是用于从MySQL中拉取事件（Command）的主要线程，在MasterServer启动时启动，通过findCommands()方法找到待执行的事件，这里的事件不仅限于开始执行工作流，还有其他类型，具体参考CommandType的定义，如下 而拉取事件流程中，如下 采用无中心节点设计，所以每个节点通过取模的方式获取当前节点应该处理的事件。节点总数和当前节点的序号是如何生成的呢？从注册中心（ZK/ETCD/JDBC）获取所有节点列表，在本地生成序号，详情参考org.apache.dolphinscheduler.service.queue.MasterPriorityQueue.ServerComparator 处理事件，创建工作流处理事件，创建工作流在，如下 而创建工作流具体分为如下几个阶段，ProcessDefinition -&gt; ProcessInstance (WorkflowInstance) -&gt; WorkflowExecuteContext -&gt; WorkflowExecuteRunnable，产生WorkflowExecuteRunnable实例即为最终需要调度的工作流 1234567891011121314// ProcessDefinition -&gt; ProcessInstance(WorkflowInstance)org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteContextFactory#createWorkflowExecuteRunnableContext:56org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteContextFactory#createWorkflowInstance:81org.apache.dolphinscheduler.service.process.ProcessServiceImpl#handleCommand:317org.apache.dolphinscheduler.service.process.ProcessServiceImpl#constructProcessInstance:768org.apache.dolphinscheduler.service.process.ProcessServiceImpl#generateNewProcessInstance:586// ProcessInstance(WorkflowInstance) -&gt; WorkflowExecuteContextorg.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnableFactory#createWorkflowExecuteRunnable:79org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteContextFactory#createWorkflowExecuteRunnableContext:67// WorkflowExecuteContext -&gt; WorkflowExecuteRunnableorg.apache.dolphinscheduler.server.master.runner.MasterSchedulerBootstrap#run:137org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnableFactory#createWorkflowExecuteRunnable:80 工作流被创建出来之后会生成一个工作流事件WorkflowEvent，放在内存的阻塞队列workflowEventQueue当中 调度工作流MasterSchedulerBootstrap线程启动后，还会再启动一个WorkflowEventLooper工作流事件处理线程，用于消费上一步放入内存的阻塞队列workflowEventQueue当中的工作流事件WorkflowEvent WorkflowEventLooper线程会使用WorkflowEventHandler处理工作流事件 WorkflowEventHandler会将通过调用WorkflowExecuteRunnable工作流的call()方法，将工作流的启动异步提交到WorkflowExecuteThreadPool线程池中执行 最终调用工作流的submitPostNode()方法，开始执行工作流的节点 解析工作流节点获取待提交的TaskNode列表submitTaskNodeList，并生成对应的TaskInstance实例TODO 解析过程比想象的复杂，需要详解分析下 将任务添加到内存中的standby优先级队列（堆）readyToSubmitTaskQueue中，并在开始提交任务 之后分发步骤比较复杂，具体拆解如下 1234567891011121314// 开始提交任务org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnable#submitStandByTask:1967// 生成任务实例（TaskExecuteRunnable）org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnable#executeTask:956// 开始分发任务实例org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnable#executeTask:993// 分发org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteRunnable#tryToDispatchTaskInstance:1011// 使用TaskDispatchOperator分发org.apache.dolphinscheduler.server.master.runner.execute.DefaultTaskExecuteRunnable#dispatch:41 // 将任务添加到globalTaskDispatchWaitingQueue中org.apache.dolphinscheduler.server.master.runner.operator.TaskDispatchOperator#handle:34// GlobalTaskDispatchWaitingQueueLooper线程轮询queue，使用BaseTaskDispatcher分发任务实例给workerorg.apache.dolphinscheduler.server.master.runner.GlobalTaskDispatchWaitingQueueLooper#run:79 最后使用找到可用worker节点，通过rpc启动待执行任务","link":"/2024/07/28/DolphinScheduler%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E6%97%A5%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89MasterServer%E5%B7%A5%E4%BD%9C%E6%B5%81%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"leetcode 33.在旋转排序数组中搜索","text":"https://leetcode.com/problems/search-in-rotated-sorted-array/description/ 33.旋转有序数组中的搜索[中等] 有一个整数数组nums，按升序排序（值各不相同）。在传递给您的函数之前，nums可能被一个未知的枢轴索引k（1 &lt;= k &lt; nums.length）旋转，使得得到的数组为[nums[k], nums[k+1], …, nums[n-1], nums[0], nums[1], …, nums[k-1]]（索引从0开始）。例如，[0,1,2,4,5,6,7]可能在枢轴索引3处旋转并变为[4,5,6,7,0,1,2]。给定可能的旋转后的数组nums和一个整数target，如果target在nums中，则返回target的索引，如果不在nums中，则返回-1。必须编写一个具有O(logn)时间复杂度的算法。 示例1：输入：nums = [4,5,6,7,0,1,2], target = 0输出：4 示例2：输入：nums = [4,5,6,7,0,1,2], target = 3输出：-1 示例3：输入：nums = [1], target = 0输出：-1 约束条件： 1 &lt;= nums.length &lt;= 5000 -10^4 &lt;= nums[i] &lt;= 10^4 nums的所有值都是唯一的。 nums是一个可能旋转的升序数组。 -10^4 &lt;= target &lt;= 10^4 解法关键点： 只有在递增区间内，且数字大小在左右边界大小之内才能够收敛区间 当[start, end]为递增区间时，只判断target和单边的关系，无法确定target是否在此区间，必须判断双边关系才能锁定target在此区间 当[start, end]为非单调增区间时，则其中可能包含任何大小的数字，比start大或者小，比end大或者小都有可能，无法收敛 指定mid的位置之后，左右两部分可能都是递增序列，而不是递增+旋转递增的序列组合 可能存在(start+end)/2=start的情况，所以必须用+1或-1进行收敛 尝试收敛时，nums[mid] &lt; target &amp;&amp; target &lt;= nums[end]为真时，nums[mid]和target一定不等，所以start可以被置为mid+1；为假时可以判断target在[start, mid]区间内，结合上面nums[mid] == target为假的条件，可以判断target如果存在则一定在[start, mid-1]区间内 12345678910111213141516171819202122232425class Solution { public int search(int[] nums, int target) { int start = 0, end = nums.length - 1; while (start &lt;= end) { int mid = (start + end) &gt;&gt; 1; if (nums[mid] == target) { return mid; } if (nums[mid] &lt;= nums[end]) { if (nums[mid] &lt; target &amp;&amp; target &lt;= nums[end]) { start = mid + 1; } else { end = mid - 1; } } else { if (nums[start] &lt;= target &amp;&amp; target &lt; nums[mid]) { end = mid - 1; } else { start = mid + 1; } } } return -1; }}","link":"/2025/04/19/leetcode-33-%E5%9C%A8%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E6%90%9C%E7%B4%A2/"},{"title":"分布式事务与CAP理论","text":"待补充","link":"/2022/07/24/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B8%8ECAP%E7%90%86%E8%AE%BA/"},{"title":"创建第一个Akka应用","text":"关于本文 版本：2.6之后的版本为收费版本，2.6版本的scala版使用文档见v2.6使用文档，flink在用的也是这个版本 api类型：classic比较灵活，试用一下classic版本的api 构建应用Demo配置如下的pom文件 pom.xml >folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;tech.bravoqq&lt;/groupId&gt; &lt;artifactId&gt;demo-akka&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;scala.version&gt;2.12.19&lt;/scala.version&gt; &lt;scala.base.version&gt;2.12&lt;/scala.base.version&gt; &lt;akka.version&gt;2.6.21&lt;/akka.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt; &lt;artifactId&gt;akka-actor_${scala.base.version}&lt;/artifactId&gt; &lt;version&gt;${akka.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt; &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt; &lt;version&gt;4.9.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;scalaVersion&gt;${scala.version}&lt;/scalaVersion&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 官方demo给到的是一个ping-pong的系统，如下， Application.scala12345678910111213141516171819202122232425262728293031323334353637383940414243444546import akka.actor.{Actor, ActorRef, ActorSystem, PoisonPill, Props}import language.postfixOpsimport scala.concurrent.duration._case object Pingcase object Pongclass Pinger extends Actor { var countDown = 100 def receive = { case Pong =&gt; println(s&quot;${self.path} received pong, count down $countDown&quot;) if (countDown &gt; 0) { countDown -= 1 sender() ! Ping } else { sender() ! PoisonPill self ! PoisonPill } }}class Ponger(pinger: ActorRef) extends Actor { def receive = { case Ping =&gt; println(s&quot;${self.path} received ping&quot;) pinger ! Pong }}object Application extends App { val system = ActorSystem(&quot;pingpong&quot;) val pinger = system.actorOf(Props[Pinger](), &quot;pinger&quot;) val ponger = system.actorOf(Props(classOf[Ponger], pinger), &quot;ponger&quot;) import system.dispatcher system.scheduler.scheduleOnce(500 millis) { ponger ! Ping }}","link":"/2024/08/07/%E5%88%9B%E5%BB%BA%E7%AC%AC%E4%B8%80%E4%B8%AAAkka%E5%BA%94%E7%94%A8/"},{"title":"pyspark分布式训练","text":"","link":"/2022/07/03/pyspark%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"title":"多线程顺序打印问题","text":"三个线程分别打印 A，B，C三个线程分别打印 A，B，C，要求这三个线程一起运行，打印 n 次，输出形如“ABCABCABC….”的字符串 使用Lock12345678910111213141516171819202122232425262728293031323334353637383940import java.util.concurrent.locks.ReentrantLock;public class ABC { static class ABCPrinter { private final int times; // 需要打印的次数 private volatile int state; // 存储状态值，打印完成时该值会变成3*time-1 private final ReentrantLock lock; public ABCPrinter(int times) { this.times = times; this.lock = new ReentrantLock(); } public void print(Character key, int num) { int current = 0; while (current &lt; times) { lock.lock(); if (state % 3 == num) { // 通过取模判断当前该哪个线程进入打印 System.out.println(key); state++; current++; } lock.unlock(); // 打印完成或非当前线程轮次会进入解锁 } } } public static void main(String[] args) throws InterruptedException { final ABCPrinter abcPrinter = new ABCPrinter(10); Thread a = new Thread(() -&gt; abcPrinter.print('A', 0)); a.start(); Thread b = new Thread(() -&gt; abcPrinter.print('B', 1)); b.start(); Thread c = new Thread(() -&gt; abcPrinter.print('C', 2)); c.start(); a.join(); b.join(); c.join(); }} 使用wait/notify12345678910111213141516171819202122232425262728293031323334353637383940414243public class ABC { static class ABCPrinter { private final static Object LOCK = new Object(); private final int times; // 需要打印的次数 private volatile int state; // 存储状态值，打印完成时该值会变成3*time-1 public ABCPrinter(int times) { this.times = times; } public void print(Character key, int num) { int current = 0; while (current &lt; times) { synchronized(LOCK){ while (state % 3 != num) { // 存在虚假唤醒的问题，必须设置为while循环 try { LOCK.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } state++; current++; System.out.println(key); LOCK.notifyAll(); // notifyAll和wait方法必须放在synchronized中，不让编译器会抛出IllegalMonitorStateException } } } } public static void main(String[] args) throws InterruptedException { final ABCPrinter abcPrinter = new ABCPrinter(10); Thread a = new Thread(() -&gt; abcPrinter.print('A', 0)); a.start(); Thread b = new Thread(() -&gt; abcPrinter.print('B', 1)); b.start(); Thread c = new Thread(() -&gt; abcPrinter.print('C', 2)); c.start(); a.join(); b.join(); c.join(); }} 两个线程交替打印0~100的奇偶数两个线程交替打印0~100的奇偶数 使用wait/notify12345678910111213141516171819202122232425262728293031323334353637public class OddEvenPrinter { static class Printer { private final static Object LOCK = new Object(); private volatile int state = 0; private final int times; public Printer(int times) { this.times = times; } public void print(int mod) { while (state &lt; times) { synchronized (LOCK) { while (state % 2 != mod) { // 处理虚假唤醒 try { LOCK.wait(); } catch (InterruptedException e) { throw new RuntimeException(e); } } System.out.println(&quot;name: &quot; + Thread.currentThread().getName() + &quot;, number: &quot; + state++); LOCK.notify(); } } } } public static void main(String[] args) { Printer printer = new Printer(100); new Thread(() -&gt; printer.print(0)).start(); new Thread(() -&gt; printer.print(1)).start(); }} 通过N个线程顺序循环打印从0至100通过N个线程顺序循环打印从0至100 使用Semaphore12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.util.concurrent.Semaphore;public class NThreadPrinter { private final int limit = 100; // 打印的最大值 private final int threadCount; // 线程数 private volatile int state = 0; // 共享状态变量 private final Semaphore[] semaphores; // 每个线程对应的信号量 public NThreadPrinter(int threadCount) { this.threadCount = threadCount; semaphores = new Semaphore[threadCount]; // 初始化信号量，除了第一个线程信号量为 1，其它为 0 for (int i = 0; i &lt; threadCount; i++) { semaphores[i] = new Semaphore(i == 0 ? 1 : 0); } } public void print(int threadId) { while (true) { try { semaphores[threadId].acquire(); // 获取当前线程的信号量 if (state &gt; limit) { semaphores[(threadId + 1) % threadCount].release(); return; } // 打印完成，退出 System.out.println(&quot;线程 &quot; + threadId + &quot; 打印：&quot; + state++); // 唤醒下一个线程 semaphores[(threadId + 1) % threadCount].release(); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { int N = 3; // 线程数量 NThreadPrinter printer = new NThreadPrinter(N); // 启动 N 个线程 for (int i = 0; i &lt; N; i++) { final int threadId = i; new Thread(() -&gt; printer.print(threadId)).start(); } }}","link":"/2025/03/08/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%A1%BA%E5%BA%8F%E6%89%93%E5%8D%B0%E9%97%AE%E9%A2%98/"},{"title":"项目回顾","text":"大数据离线任务调度系统定义大数据离线任务调度系统 是指用于 管理、编排和执行批处理（离线）数据任务 的平台，它确保 数据在正确的时间、以正确的依赖关系顺序、在正确的计算资源上被处理，以支持数据仓库建设、ETL流程、数据分析、数据报表等工作。上下游关联：上层是数据开发平台、BI平台、机器学习平台等等，下层是Spark、MR、异步数据源同步引擎等底层引擎运行频率：一般是分钟级、小时级、日级 痛点问题 调度时延高：对于到达就绪时间的任务，旧架构下采取轮询的模式从DB查询任务，时延较高 有状态服务：服务内存中存储DAG结构，服务重启或故障情况下需要恢复内存状态 单点问题：服务发布、单点故障会导致服务不可用。 关键设计事件驱动+分布式非阻塞设计，有效降低任务和链路的调度时延 优点： 异步非阻塞：使得系统响应速度更快，延迟更低 扩展性强：事件可以作为切面，可以支持更丰富的hook逻辑，而不阻塞主业务逻辑 高可用：事件缓存在消息队列，部分服务器上的服务异常，不会影响服务整体的可用性 挑战： 事件幂等：事件消息生产-消费的过程中，为了避免网络问题等导致流程异常中断，一定会做重试。所以要对事件的处理做幂等处理。通过【状态机+事件去重】来做幂等 事件乱序并发：状态机校验+partition分区，同一任务相关事件单线程处理，类似actor模式，避免复杂的并发处理，避免在任务粒度上加分布式锁带来的性能开销 “无状态”服务基于缓存中间件存储DAG结构，服务重启或单点故障时无需做状态恢复 组件选型定时触发任务Quartz vs 延迟队列（kafka+tair时间轮） 消息队列Kafka vs rabbitMQ vs RocketMQ 分布式内存Redis-cluster vs Tair 分布式协调服务ZooKeeper vs ETCD 详细设计延迟队列：对比Quartz等分布式方案，没有使用分布式锁，而是基于kafka+tair用时间轮实现，延迟更低事件消费速度：partition单线程拉取+多线程批量消费，滑动窗口ACK分布式有序提交：mr模式，map基于sorted set设计的优先级队列，reduce采用dispacther线程单线程提交，多实例采用zk公平锁实现均衡自动容错：服务重启，节点宕机情况下能自动容错。注册中心zk不停机运维：版本号的事件设计，运维操作需要与调度并行，对于子DAG的运维需要在不影响其他任务的前提下，不受非运维消息的影响 问题与解决方案Q：单线程dispatcher缓存操作效率低A：批处理+pipeline Q：未知原因导致调度慢？CPU指标较高？A：redis监控，服务日志无异常。Arthas火焰图大部分时间做监控数据上报，调小监控上报的线程池大小 Q：kafka partition批量消费加了内存锁，一个事件处理线程卡住？A：jstack发现一个线程卡住，定位到实现的一个LockManager对于unlock操作不当 Q：上游触发下游执行时给事件赋值版本号，此时可能同时存在运维动作A：版本号+上游依赖版本 大数据资产管理与治理平台提升数据资产(Hive 表、Spark、Flink 任务等)全方位可视化管理、优化资源利用、实现智能治理，并提供量化收益评估，最终推动资源合理使用，提高数据资产的整体价值 痛点问题业务痛点：分区生命周期应该配置多久？如果发现无效的离线数仓表/任务？怎么常态化推动持续治理？技术难点：复杂业务流程建模、流程自动化、流程可视化。等待用户确认，操作分区数据等能力做抽象，具备复用能力 关键设计fe：主要负责资产360，资产问题发现与治理spark+hive/es构建资产元数据，SpringBoot+es+doris搭建资产管理与治理系统。定义问题资产评估标准，定期扫描百万级数据表/任务，辅助定位资源问题，同时提供治理流程追踪与自动化治理，提升治理效率be：主要承载资产管理能力，如表及分区周期清理、降低副本、ORC压缩spiffworkflow：python实现的一套BPMN workflow框架，组织各种同步/异步任务的处理流程celery：异步任务处理","link":"/2025/04/18/%E9%A1%B9%E7%9B%AE%E5%9B%9E%E9%A1%BE/"},{"title":"操作系统","text":"操作系统相关书籍：《Linux是怎样工作的 - [日]武内觉》 存储层次高速缓存从内存直接和寄存器之间做数据拷贝很慢，高速缓存的存在，正是为了抹平寄存器与内存之间的性能差距。 读取数据从内存读取数据时，数据显呗送往高速缓存，在被送往寄存器，读取的数据大小取决于缓存块大小（cache line size），该值由各个CPU规定。假设缓存块的大小为 10 字节，高速缓存的容量为 50 字节，并且存在两个长度为 10 字节的寄存器（R0 与 R1）。在这样的运行环境下，把内存地址 300 上的数据读取到 R0 时的情形如图 6-2 所示。此后，当 CPU 需要再次读取地址 300 上的数据时，比如需要再次把同样的数据读取到 R1 时，将不用从内存读取数据，只需读取已经存在于高速缓存上的数据即可 写入数据当需要将寄存器上的数据重新写回到地址 300 上时，首先会把改写后的数据写入高速缓存，如图 6-5 所示。此时依然以缓存块大小为单位写入数据。然后，为这些缓存块添加一个标记，以表明这部分从内存读取的数据被改写了。通常我们会称这些被标记的缓存块“脏了”。这些被标记的数据会在写入高速缓存后的某个指定时间点，通过后台处理写入内存。随之，这些缓存块就不再脏了 [3]，如图 6-6 所示。也就是说，只需要访问速度更快的高速缓存，即可完成图 6-5 中的写入操作","link":"/2025/04/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"计算机知识拓扑","text":"计算机知识拓扑操作系统、计算机网络、数据结构、编程语言等","link":"/2025/03/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9F%A5%E8%AF%86%E6%8B%93%E6%89%91/"},{"title":"编程语言-Java","text":"概念编译型语言和解释型语言的区别 编译型语言：在程序执行之前，整个源代码会被编译成机器码或者字节码，生成可执行文件。执行时直接运行编译后的代码，速度快，但跨平台性较差。 解释型语言：在程序执行时，助航解释执行源代码，不生成独立的可执行文件。通常由解释器动态解释并执行代码，跨平台性好，但执行速度相对较慢。典型的编译型语言如C、C++，但型的解释型语言如Python、JavaScript 数据类型基础数据类型及其包装类型，缓存池关于几种初始化Integer方式，初始化对象的区别 代码示例 >folded12345678910111213141516171819202122public class Main { public static void main(String[] args) { Integer i = new Integer(100); Integer j = new Integer(100); System.out.println(i == j); // false new每次在堆生成新的对象 Integer i = new Integer(100); Integer j = 100; System.out.println(i == j); // false new新建堆对象，自动装箱使用Integer.valueOf，会尝试获取缓存的对象（-128～127） Integer i = 100; Integer j = 100; System.out.println(i == j); // true 获取的时缓存池中的对象 Integer i = 128; Integer j = 128; System.out.println(i == j); // false 超过缓存池范围 i = new Integer(100); int k = 100; System.out.println(1 == k); // true 包装数据类型之间比较的是内存地址，基本数据类型之间比较的是值，包装数据类型和基本数据类型比较，会先拆箱成基本数据类型，所以比的也是值 }} 面向对象特性：封装、继承、多态泛型集合Java内存模型 JMM多线程JVMJVM内存区域 程序计数器：线程私有的，jvm通过改变计数器的值来选取下一条需要执行的字节码指令，唯一一个没有规定任何OutOfMemoryError情况的区域 Java虚拟机栈：线程私有的，每个方法执行时创建栈帧，方法被调用就是栈帧在栈中从入栈到出栈的过程。栈帧的组成部分如下， 局部变量表：存放编译期可知的各种jvm基本数据类型、对象引用。todo 待完善 操作数栈： 动态链接： 方法返回地址： 本地方法栈：线程私有的，本地（Native）方法所使用的栈 Java堆：线程共享的，分配内存创建存储对象实例的主要内存区域。在即时编译（JIT）的栈上分配、标量替换等技术下，也可以分配在其他区域 分配缓冲区：即TLAB（Thread Local Allocation Buffer），用于优化内存分配速度，避免线程并行导致分配内存冲突而提前为线程预留内存 方法区：线程共享的，也称永久代，用于存储已被jvm加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。在jdk8以后被本地内存中实现的元空间（Meta-space）代替 运行时常量池：方法区的一部分。Class文件中除了类版本、字段、方法、接口等信息外，还有一项信息是常量池表，用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中 直接内存：不是jvm运行时数据区的一部分，NIO中使用，基于Channel与Buffer的I/O方式，直接分配堆外内存，避免java堆和Native堆之间的数据赋值，从而显著提升性能 类加载机制类加载时机 new实例化类对象，读取或者设置类的静态字段（final修饰编译期把结果放入常量池的静态字段除外），调用一个类的静态方法时 对类型进行反射调用 当初始化子类的时候，发现父类还未初始化，会初始化父类 … 类的生命周期 加载 验证 准备 解析 初始化 使用 卸载：卸载的前提有3个 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象 该类没有在其他任何地方被引用 该类的类加载器的实例已被 GC 类加载器机制三层类加载器、双亲委派的类加载架构 类加载器（Class Loader） 启动类加载器（Bootstrap Class Loader）：C++语言编写，JVM的一部分。责加载存放在&lt;JAVA_HOME&gt;\\lib目录，或者被-Xbootclasspath参数所指定的路径中存放的，而且是Java虚拟机能够识别的类库加载到虚拟机的内存中 扩展类加载器（Extension Class Loader）：负责加载&lt;JAVA_HOME&gt;\\lib\\ext目录中，或者被java.ext.dirs系统变量所指定的路径中所有的类库 应用程序类加载器（Application Class Loader）：也称为“系统类加载器”。它负责加载用户类路径（ClassPath）上所有的类库，开发者同样可以直接在代码中使用这个类加载器 双亲委派模型双亲委派模型的工作过程：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载 破坏双亲委派模型 线程上下文类加载器 SPI OSGi 类的卸载条件对象的创建过程 常量池中尝试定位类的符号引用，判断类是否被加载、解析和初始化过。如果没有先做类加载 为对象分配内存。内存规整使用“指针碰撞”，内存零散使用“空闲列表”。处理线程申请内存的冲突，可以选择使用cas失败重试或者TLAB 内存空间初始化为零值，（TLAB方式也可以提前到TLAB分配时进行） 初始化对象头信息，类的元数据信息、哈希码、对象的gc分代年龄。根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式 垃圾回收理论判断对象是否应该被回收 引用计数法：引用一次计数+1。存在循环引用的问题，比如map大对象需要嵌套引用关系 可达性分析：通过GC Roots根据引用关系向下搜索，到达不了的对象就是需要被回收的 可作为GC Roots的对象： 虚拟机栈中引用的对象，比如参数、局部变量、临时变量等 类静态属性引用的变量 常量引用的对象 JNI引用的对象 sychronized同步锁持有的对象 … 垃圾回收算法 分代收集理论：根据以下理论，一般将jvm堆划分成新生代和老年代，对不通的区域单独进行gc 弱分代假说：绝大多数对象都是朝生夕灭的 强分代假说：熬过越多次垃圾回收的对象就越难被回收 标记-清除算法：标记阶段，标记所有需要回收的对象，回收阶段，统一回收掉所有被标记的对象。但是存在如下缺点 当存在大量对象需要被回收时，标记和回收的效率随着对象增多而降低 内存空间碎片化，大对象无法分配足够的连续内存，而引发额外的gc动作 标记-复制算法：也叫做复制算法。针对的新生代对象的存亡特征：朝生夕灭。将堆划分成一块Eden空间和两块较小的Survivor空间（默认8:1），每次只用一块Eden空间和一块Survivor空间，每次gc时将存活的对象复制到剩下的一块Survivor空间中，清除Eden空间和使用过的Survivor空间。Survivor空间不足一次gc的时候，一般会用老年代做分配的担保 标记-整理算法：针对老年代独享的存亡特征：难以回收。标记阶段同“标记-清除算法”，清理阶段让所有存活的对象都向内存空间的一端移动，然后直接清理掉边界以外的内存 注：标记-清除算法所带来的jvm停顿会更小，但是由于内存分配和访问的频率比gc要高，标记-整理算法的吞吐量会更高。所以关注延迟的CMS是基于标记-清除算法的，关注吞吐的Parallel Scavenge是基于标记-整理算法的 回收相关算法细节 根结点枚举：方法区比较大，查找GC Root耗时较长。使用OopMap直接存放对象引用位置，提高查找效率 安全点：在执行到“长时间执行”的位置生成OopMap，这些位置被称为安全点。这些位置是执行序列复用的地方，比如方法调用、循环跳转、异常跳转 线程执行到安全点如何停顿：抢占式中断，一般不用。主动式中断，设置标志位等待线程运行到安全点自己主动挂起 安全区域：未分配到时间分片的线程，如sleep或者blocked状态的线程。这种能确保在某一段代码中，引用关系不会发生变化的区域，被称为安全区域 记忆集与卡表：新生代和老年代之间可能存在引用关系，为了避免对新生代回收时扫描整个老年代，在新生代中建立了记忆集的数据结构。卡表是记忆集的一种具体实现，定义了记忆集的记录精度，与堆内存的映射关系等，卡表标识的每一个内存块叫卡页，存在跨代引用会将卡页刷脏，脏页在回收时是需要被扫描的 写屏障：写屏障可以看作在虚拟机层面对“引用类型字段赋值”这个动作的AOP切面，在这个切面上可以维护卡表状态 并发的可达性分析：使用三色标记法实现 颜色种类 白色：对象尚未被垃圾收集器访问过。分析开始所有对象是白色，分析结束只有不可达的对象是白色 黑色：表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色对象不可能指向白色对象 灰色：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过 如何避免对象误标记：用户线程和标记线程并发运行，可能标记过后节点是白色但是新增了引用关系应该为黑色，如果不处理，该节点会被错误地回收掉 误标记出现条件 增加了一条或者多条从黑色对象到白色对象的引用 删除了全部从灰色对象到白色对象的直接或间接引用 解决方案：（两种方案任选其一） 增量更新（Incremental Update）：新增黑色指向白色的引用时，记录这个引用关系。并发扫描结束之后，再以黑色对象为根重新扫描一次。CMS的实现方式 原始快照（SATB，Snapshot At The Beginning）：删除灰色指向白色的引用时，记录这个引用关系。并发扫描结束之后，再以灰色对象为根重新扫描一次。G1、Shenandoah的实现方式 垃圾回收器垃圾回收器之间的组合关系 Serial收集器特点：gc时必须暂停其他工作线程直至gc结束优点：简单高效，额外内存开销小，适用于资源受限的环境。客户端模式下可以使用，比如桌面应用缺点：停顿时间较长，体验较差 ParNew收集器特点：Serial收集器的多线程并行版本。除了Serial收集器外，目前只有它能与CMS收集器配合工作 Parallel Scanvenge收集器特点：新生代收集器，基于标记-复制算法实现，也是能并行收集的多线程收集器。该收集器目标是达到一个可控制的吞吐量。-XX：MaxGCPauseMillis设置最大停顿时间，设置越小相对地gc越频繁，-XX：GCTimeRatio设置gc时间占总时间的比例。除此之外，-XX：+UseAdaptiveSizePolicy可以设置自适应调节，无需指定Eden，Survivor区大小，收集器会自动调节以做到最优吞吐 Serial Old收集器特点：是Serial收集器的老年代版本，单线程收集器，使用标记-整理算法。该收集器的主要意义也是供客户端模式下的JVM使用。服务端模式下，有两种用途，一是JDK 5以及之前的版本中与Parallel Scavenge收集器搭配，二是另外一种就是作为CMS收集器发生失败时的后备预案，在并发收集发生Concurrent Mode Failure时使用 Parallel Old收集器特点：Parallel Old是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现。在注重吞吐量或者处理器资源较为稀缺的场合，都可以优先考虑这个组合 CMS收集器特点：一种以获取最短回收停顿时间为目标的收集器，基于标记-清除算法实现的步骤： 1. 初始标记：标记一下GC Roots能直接关联到的对象，停顿较短 2. 并发标记：从GC Roots的直接关联对象开始遍历整个对象图，与用户线程并发 3. 重新标记：为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，停顿较长 4. 并发清除：清理删除掉标记阶段判断的已经死亡的对象，与用户线程并发 初始标记、重新标记两步需要“Stop The World” 优点： 并发收集，低停顿 缺点： 对处理器资源非常敏感。在并发阶段，它虽然不会导致用户线程停顿，但却会因为占用了一部分cpu资源而导致应用程序变慢，降低总吞吐量 无法处理“浮动垃圾”，可能出现“Concurrent Mode Failure”失败进而导致另一次完全“Stop The World”的Full GC的产生。CMS运行期间预留的内存无法满足程序分配新对象，即“Concurrent Mode Failure”，需要临时启用Serial Old收集器来重新进行老年代的垃圾收集 浮动垃圾：并发标记和并发清理阶段，用户线程还在继续运行，程序在运行不断产生新的垃圾对象，但这部分垃圾无法在当次GC被标记处理，只好留待下一次GC时再清理。这一部分垃圾就称为“浮动垃圾” 收集结束时会有大量空间碎片产生。碎片过多时，往往会出现老年代还有很多剩余空间，但无法找到足够大的连续空间来分配当前对象，而不得不提前触发一次Full GC的情况。-XX：+UseCMS-CompactAtFullCollection参数可以指定full gc时整理内存碎片，-XX：CMSFullGCsBefore-Compaction参数可以指定进行n次不整合碎片的full gc之后，下次full gc之前先整理碎片 Garbage First收集器（G1）特点：基于Region的内存布局形式，面向服务端应用的垃圾收集器。建立起“停顿时间模型”，把连续的Java堆划分为多个大小相等的独立区域（Region），每一个Region根据需要，扮演新生代的Eden空间、Survivor空间，或老年代空间。将Region作为单次回收的最小单元，后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间（-XX：MaxGCPauseMillis），优先处理回收价值收益最大的那些Region。每个Region都维护有自己的记忆集，G1至少要耗费大约相当于Java堆容量10%至20%的额外内存来维持收集器工作 停顿时间模型：能够支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标 步骤： 1. 初始标记：标记一下GC Roots能直接关联到的对象，停顿较短 2. 并发标记：从GC Roots的直接关联对象开始遍历整个对象图，与用户线程并发 3. 最终标记：对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录，停顿较短 4. 筛选回收：更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据期望的停顿时间制定回收计划，把决定回收的部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的全部空间，涉及存活对象的移动，必须暂停用户线程 G1收集器除了并发标记外，其余阶段也是要完全暂停用户线程的，换言之，它并非纯粹地追求低延迟，官方给它设定的目标是在延迟可控的情况下获得尽可能高的吞吐量 优点： 可以指定最大停顿时间、分Region内存布局、收益动态确定回收集合 从整体来看是基于“标记-整理”算法实现的收集器，但从局部（两个Region之间）上看又是基于“标记-复制”算法实现，不会产生内存空间碎片 缺点： 额外内存占用和执行负载比CMS要高（Region粒度的卡表，以及卡表更复杂的维护） 版本特性","link":"/2025/03/30/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-Java/"},{"title":"leetcode 45.跳跃游戏II","text":"https://leetcode.com/problems/jump-game-ii/ 45.跳跃游戏 II 你被给了一个长度为 n 的整数数组 nums，索引从 0 开始。你最初位于 nums[0]。数组中的每个元素 nums[i] 代表从索引 i 出发的最大向前跳跃长度。换句话说，如果你在 nums[i]，你可以跳到任何 nums[i + j]，其中： 0 &lt;= j &lt;= nums[i] 且 i + j &lt; n返回到达 nums[n - 1] 的最小跳跃次数。测试用例生成保证你可以到达 nums[n - 1]。 示例 1：输入：nums = [2,3,1,1,4]输出：2解释：到达最后一个索引的最小跳跃次数是 2。从索引 0 跳 1 步到 1，然后跳 3 步到达最后一个索引。 示例 2：输入：nums = [2,3,0,1,4]输出：2 约束条件： 1 &lt;= nums.length &lt;= 10^4 0 &lt;= nums[i] &lt;= 1000 保证你可以到达 nums[n - 1]。 动态规划算法创建一个用于存储状态的数组minStepNums，用于存储位置i跳到最后位置所需的最小步数minStepNums[i]，对i位置来说可以到达的位置是(i, i+nums[i]]，假设里面的位置j具备最小的minStepNums[j]，则对于i位置来说到达最后位置所需的最小步数为minStepNums[i]=minStepNums[j]+1时间复杂度：O(n^2) 1234567891011121314151617class Solution { public int jump(int[] nums) { int[] minStepNums = new int[nums.length]; Arrays.fill(minStepNums, Integer.MAX_VALUE); // 初始化为最大值 minStepNums[nums.length - 1] = 0; for (int i = nums.length - 2; i &gt;= 0; i--) { int minStepNum = Integer.MAX_VALUE; for (int j = i + 1; j &lt;= i + nums[i] &amp;&amp; j &lt; nums.length; j++) { if (minStepNums[j] != Integer.MAX_VALUE) { // 为了防止溢出 minStepNum = Math.min(minStepNum, minStepNums[j] + 1); } } minStepNums[i] = minStepNum; } return minStepNums[0]; }} 贪心算法记录跳跃次数steps的同时，记录当前跳跃次数可到的的最远位置currentMaxPos，一边移动当前位置，一边判断情况 已经到达当前steps可到达的最远距离currentMaxPos，此时不得不跳跃一次，同时刷新currentMaxPos currentMaxPos的刷新：已经走过的位置可以根据每个位置的最大跳远距离，计算出下一次跳跃的最远距离nextMaxPos，跳完之后用这个值刷新currentMaxPos就可以了 还没到达currentMaxPos，可以跳可以不跳，但是不跳肯定是次数最少的123456789101112131415class Solution { public int jump(int[] nums) { int steps = 0; int currentMaxPos = 0; int nextMaxPos = 0; for (int i = 0; i &lt; nums.length - 1; i++) { nextMaxPos = Math.max(i + nums[i], nextMaxPos); if (i == currentMaxPos) { steps++; currentMaxPos = nextMaxPos; } } return steps; }} Q：加深一下，如果题目没有保证最后的位置一定可达，那怎么办？A：移动i之后先做i &gt; currentMaxPos的判断，如果大于了，说明无法到达此位置，直接返回-1就可以了","link":"/2025/04/27/leetcode-45-%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8FII/"}],"tags":[{"name":"Akka","slug":"Akka","link":"/tags/Akka/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"DolphinScheduler","slug":"DolphinScheduler","link":"/tags/DolphinScheduler/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"CAP","slug":"CAP","link":"/tags/CAP/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"项目回顾","slug":"项目回顾","link":"/tags/%E9%A1%B9%E7%9B%AE%E5%9B%9E%E9%A1%BE/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"categories":[{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"调度服务","slug":"调度服务","link":"/categories/%E8%B0%83%E5%BA%A6%E6%9C%8D%E5%8A%A1/"},{"name":"Interview","slug":"Interview","link":"/categories/Interview/"},{"name":"Database","slug":"Database","link":"/categories/Database/"},{"name":"🍺 Code Interview","slug":"Interview/🍺-Code-Interview","link":"/categories/Interview/%F0%9F%8D%BA-Code-Interview/"},{"name":"分布式","slug":"Interview/分布式","link":"/categories/Interview/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"项目回顾","slug":"Interview/项目回顾","link":"/categories/Interview/%E9%A1%B9%E7%9B%AE%E5%9B%9E%E9%A1%BE/"},{"name":"操作系统","slug":"Interview/操作系统","link":"/categories/Interview/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"0.知识拓扑","slug":"Interview/0-知识拓扑","link":"/categories/Interview/0-%E7%9F%A5%E8%AF%86%E6%8B%93%E6%89%91/"},{"name":"编程语言","slug":"Interview/编程语言","link":"/categories/Interview/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}]}